{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "# Lab 2 - Classification\n",
    "\n",
    "Team: Frank Sclafani, Jan Shook, and Leticia Valadez\n",
    "\n",
    "## TV News Channel Commercial Detection\n",
    "\n",
    "Our team selected this dataset for two reasons: 1) It has a large number of instances (129,685, which is greater than the requirement of at least 30,000) and enough attributes (14, which is greater than the requirement of at least 10), and 2) It looks like an interesting dataset (detecting commercials). Initial questions of interest are how do you detect commercials from this data? Can a model be trained to detect and skip (or remove) commercials? If so, would this solution be robust enough for commercial products like TiVo?\n",
    "\n",
    "This dataset is from the UCI Machine Learning website (https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset). It consists of popular audio-visual features of video shots extracted from 150 hours of TV news broadcast of 3 Indian and 2 international news channels (30 Hours each). In the readme accompanying the data, the authors describe the potential benefits of this data as follows:\n",
    "\n",
    "> Automatic identification of commercial blocks in news videos finds a lot of applications in the domain of television broadcast analysis and monitoring. Commercials occupy almost 40-60% of total air time. Manual segmentation of commercials from thousands of TV news channels is time consuming, and economically infeasible hence prompts the need for machine learning based Method. Classifying TV News commercials is a semantic video classification problem. TV News commercials on particular news channel are combinations of video shots uniquely characterized by audio-visual presentation. Hence various audio visual features extracted from video shots are widely used for TV commercial classification. Indian News channels do not follow any particular news presentation format, have large variability and dynamic nature presenting a challenging machine learning problem. Features from 150 Hours of broadcast news videos from 5 different (3 Indian and 2 International News channels) news channels. Viz. CNNIBN, NDTV 24X7, TIMESNOW, BBC and CNN are presented in this dataset. Videos are recorded at resolution of 720 X 576 at 25 fps using a DVR and set top box. 3 Indian channels are recorded concurrently while 2 International are recorded together. Feature file preserves the order of occurrence of shots.\n",
    "\n",
    "### Objective: Classify Video Attributes as Commercial or Non-commercial\n",
    "\n",
    "This dataset has already been classified as commercial (+1) or non-commercial (-1) in the Dimension Index attribute. Hence, in subsequent analysis, we will be able to train and compare our data models against the target variable that has already created to determine the effectiveness of the model.\n",
    "\n",
    "### Techniques Applied in this Project\n",
    "\n",
    "#### Data Preparation\n",
    "\n",
    "> The SVM Light approach to persisting sparse matrix arrays was used loaded into a Pandas dataframe\n",
    "\n",
    "> The X and Y axis in the SVM Light approach was combined into a two-dimensional Pandas dataframe\n",
    "\n",
    "> Columns that have little merit to the intial analysis were deleted\n",
    "\n",
    "> Pandas columns with empty values (i.e., all zeroes) were deleted\n",
    "\n",
    "> Different type of row and / or columns were separated into different dataframes to analyize the data differently\n",
    "\n",
    "#### Data Visualization\n",
    "\n",
    "> The Hexagon Bin Plot was used to visualize the complete dataset, and it appears a linear coorelation exists among attributes\n",
    "\n",
    "> Individual scatter plots were created for each attribute (non-bin related)\n",
    "\n",
    "## About this Notebook\n",
    "\n",
    "This Jupyter (v4.3.0) notebook was developed on Windows 10 Pro (64 bit) using Anaconda v4.4.7 and Python v3.*.\n",
    "\n",
    "Packages associated with Anaconda were extracted as follows:\n",
    "\n",
    "> conda install -c anaconda pandas\n",
    "\n",
    "> conda install -c anaconda numpy \n",
    "\n",
    "In addition to the packages in Anaconda (and outside of the Anaconda ecosystem), this notebook uses Plotly (v2.2.3) for visualization. The zip file for Plotly can be found on GitHub at (https://github.com/plotly/plotly.py). You can install the Plotly packages as follows:\n",
    "\n",
    "> pip install plotly\n",
    "\n",
    "The version of Pandas and its dependencies are shown below.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* <a href=\"#Section 1: Data Understanding\">Section 1: Data Understanding</a>  \n",
    "> <a href=\"#Section 1.1: About this Dataset (Summary)\">Section 1.1: About this Dataset (Summary)</a>  \n",
    "> <a href=\"#Section 1.2: Description of the Attributes\">Section 1.2: Description of the Attributes</a>  \n",
    "> <a href=\"#Section 1.3: Potentially Useful Attribues\">Section 1.3: Potentially Useful Attribues</a>  \n",
    "> <a href=\"#Section 1.4: Columns and Data Types\">Section 1.4: Columns and Data Types</a>  \n",
    "\n",
    "* <a href=\"#Section 2: Data Preparation\">Section 2: Data Preparation</a>  \n",
    "> <a href=\"#Section 2.1: Download Files\">Section 2.1: Download Files</a>  \n",
    "> <a href=\"#Section 2.2: Pivot the Y-axis\">Section 2.2: Pivot the Y-axis</a>  \n",
    "> <a href=\"#Section 2.3: Convert Sparse Matrix Array to an Array\">Section 2.3: Convert Sparse Matrix Array to an Array</a>  \n",
    "> <a href=\"#Section 2.4: Concatenate the Y-axis before the X-axis\">Section 2.4: Concatenate the Y-axis before the X-axis</a>  \n",
    "> <a href=\"#Section 2.5: Convert the Arrays into Pandas Dataframes\">Section 2.5: Convert the Arrays into Pandas Dataframes</a>  \n",
    "> <a href=\"#Section 2.6: Rename Columns from Integers to Labels\">Section 2.6: Rename Columns from Integers to Labels</a>    \n",
    "> <a href=\"#Section 2.7: Inspecting Missing Values\">Section 2.7: Inspecting Missing Values</a>  \n",
    "> <a href=\"#Section 2.8: Concatenate the Five Pandas Dataframes\">Section 2.8: Concatenate the Five Pandas Dataframes</a>  \n",
    "\n",
    "* <a href=\"#Section 3: Visualizing the Data\">Section 3: Visualizing the Data</a>  \n",
    "\n",
    "* <a href=\"#Section 4: Modeling\">Section 4: Modeling</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.6.3.final.0\n",
      "python-bits: 64\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 42 Stepping 7, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: None\n",
      "LOCALE: None.None\n",
      "\n",
      "pandas: 0.20.3\n",
      "pytest: 3.2.1\n",
      "pip: 9.0.1\n",
      "setuptools: 36.5.0.post20170921\n",
      "Cython: 0.26.1\n",
      "numpy: 1.13.3\n",
      "scipy: 1.0.0\n",
      "xarray: None\n",
      "IPython: 6.1.0\n",
      "sphinx: 1.6.3\n",
      "patsy: 0.4.1\n",
      "dateutil: 2.6.1\n",
      "pytz: 2017.2\n",
      "blosc: None\n",
      "bottleneck: 1.2.1\n",
      "tables: 3.4.2\n",
      "numexpr: 2.6.2\n",
      "feather: None\n",
      "matplotlib: 2.1.1\n",
      "openpyxl: 2.4.8\n",
      "xlrd: 1.1.0\n",
      "xlwt: 1.3.0\n",
      "xlsxwriter: 1.0.2\n",
      "lxml: 4.1.0\n",
      "bs4: 4.6.0\n",
      "html5lib: 0.999999999\n",
      "sqlalchemy: 1.1.13\n",
      "pymysql: None\n",
      "psycopg2: None\n",
      "jinja2: 2.9.6\n",
      "s3fs: None\n",
      "pandas_gbq: None\n",
      "pandas_datareader: None\n",
      "Wall time: 7.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Runtime Expectation: The following cell runs about 30 seconds on the first execution of this notebook, and a second or two after that.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.show_versions()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 1: Data Understanding\"></a>\n",
    "\n",
    "# Section 1: Data Understanding\n",
    "\n",
    "<a id=\"Section 1.1: About this Dataset (Summary)\"></a>\n",
    "\n",
    "## Section 1.1: About this Dataset (Summary)\n",
    "\n",
    "This project is comprised of five datasets (bbc.txt, cnn.txt, cnnibn.txt, ndtv.txt, and timesnow.txt), all found at the UCI Machine Learning webset at https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset. Combined, these five datasets have 129,685 instances (rows) and 14 attributes. As shown in the example record below, most of these attributes have multiple data points (often hundreds) and almost all of these values are floating point.\n",
    "\n",
    "> 1  1:123 2:1.316440 3:1.516003 4:5.605905 5:5.346760 6:0.013233 7:0.010729 8:0.091743 9:0.050768 10:3808.067871 11:702.992493 12:7533.133301 13:1390.499268 14:971.098511 15:1894.978027 16:114.965019 17:45.018257 18:0.635224 19:0.095226 20:0.063398 21:0.061210 22:0.038319 23:0.018285 24:0.011113 25:0.007736 26:0.004864 27:0.004220 28:0.003273 29:0.002699 30:0.002553 31:0.002323 32:0.002108 33:0.002036 34:0.001792 35:0.001553 36:0.001250 37:0.001317 38:0.001084 39:0.000818 40:0.000624 41:0.000586 42:0.000529 43:0.000426 44:0.000359 45:0.000446 46:0.000268 47:0.000221 48:0.000154 49:0.000217 50:0.000193 51:0.000163 52:0.000165 53:0.000210 54:0.000114 55:0.000130 56:0.000055 57:0.000013 58:0.733037 59:0.133122 60:0.041263 61:0.019699 62:0.010962 63:0.006927 64:0.004525 65:0.003128 66:0.002314 67:0.001762 68:0.001361 69:0.001065 70:0.000914 71:0.000777 72:0.000667 73:0.000565 74:0.000520 75:0.000467 76:0.000469 77:0.000486 78:0.000417 79:0.000427 80:0.000349 81:0.000258 82:0.000262 83:0.000344 84:0.000168 85:0.000163 86:0.001058 90:0.020584 91:0.185038 92:0.148316 93:0.047098 94:0.169797 95:0.061318 96:0.002200 97:0.010440 98:0.004463 100:0.010558 101:0.002067 102:0.338970 103:0.470364 104:0.189997 105:0.018296 106:0.126517 107:0.047620 108:0.045863 109:0.184865 110:0.095976 111:0.015295 112:0.056323 113:0.024587 115:0.037647 116:0.006015 117:0.160327 118:0.251688 119:0.176144 123:0.006356 219:0.002119 276:0.002119 296:0.341102 448:0.099576 491:0.069915 572:0.141949 573:0.103814 601:0.002119 623:0.050847 726:0.038136 762:0.036017 816:0.036017 871:0.016949 924:0.008475 959:0.036017 1002:0.006356 1016:0.008475 1048:0.002119 4124:0.422333825949 4125:0.663917631952\n",
    "\n",
    "All five datasets are formated in the svmlight / libsvm format. This format is a text-based format, with one sample per line. It is a light format meaning it does not store zero valued features, every fetature that is \"missing\" has a value of zero. The first element of each line is used to store a target variable, and in this case it is the vaue of the atriburtes below. \n",
    "\n",
    "Hence, the file simply contains more records like the one shown above. While there are only 14 attributes in each dataset, most attributes can have more than one column of data. \n",
    "\n",
    "<a id=\"Section 1.2: Description of the Attributes\"></a>\n",
    "\n",
    "## Section 1.2: Description of the Attributes\n",
    "\n",
    "The following sections describe this dataset using the Readme.txt file, examination of the data, and definition of the terms.\n",
    "\n",
    "### Dimension Index (Dependent Variable)\n",
    "\n",
    "This is the dependent variable of Commercial (+1) or Non-Commercial (-1) (i.e., the classification).\n",
    "\n",
    "### Shot Length\n",
    "\n",
    "Commercial video shots are usually short in length, fast visual transitions with peculiar placement of overlaid text bands. Video Shot Length is directly used as one of the feature.\n",
    "\n",
    "### Short time energy\n",
    "\n",
    "Short term energy (STE) can be used for voiced, unvoiced and silence classification of speech. The relation for finding the short term energy can be derived from the total energy relation defined in signal processing. STE is defined as sum of squares of samples in an audio frame. To attract user’s attention commercials generally have higher audio amplitude leading to higher STE.\n",
    "\n",
    "### ZCR\n",
    "Zero Crossing Rate (ZCR) is the rate of sign-changes along a signal. This is used in both speech recognition and music information retrieval and it is a feature used to classify sounds. That is precisely its use here in this dataset, it will be used as one of the attributes to help differentiate commercials from the news program. The Zero Crossing Rate measures how rapidly an audio signal changes. ZCR varies significantly for non-pure speech (High ZCR), music (Moderate ZCR) and speech (Low ZCR). Usually commercials have background music along with speech and hence the use of ZCR as a feature. Audio signals associated with commercials generally have high music content and faster rate of signal change compared to that of non-commercials.\n",
    "\n",
    "### Spectral Centroid\n",
    "\n",
    "Spectral Centroid is a measure of the “center of gravity” using the Fourier transform's frequency and magnitude information. It is commonly used in digital signal processing to help characterize a spectrum. This motivated the use of spectral features where higher Spectral Centroid signify higher frequencies (music).\n",
    "\n",
    "### Spectral Roll off\n",
    "\n",
    "Spectral Roll off Point is a measure of the amount of the right-skewedness of the power spectrum. This feature discriminates between speech, music and non-pure speech.\n",
    "\n",
    "### Spectral Flux\n",
    "\n",
    "Spectral flux is a measure of how quickly the power spectrum of a signal changes. It is calculated by comparing the power spectrum for one frame against the power spectrum from the previous frame.\n",
    "\n",
    "### Fundamental Frequency\n",
    "\n",
    "The fundamental frequency is the lowest frequency of a waveform. In music, the fundamental is the musical pitch of a note that is perceived as the lowest fundamental frequency present. This feature is also used as non-commercials (dominated by pure speech) will produce lower fundamental frequencies compared to that of commercials (dominated by music).\n",
    "\n",
    "### Motion Distribution\n",
    "\n",
    "Motion Distribution is obtained by first computing dense optical flow (Horn-Schunk formulation) followed by construction of a distribution of flow magnitudes over the entire shot with 40 uniformly divided bins in range of [0, 40]. Motion Distribution is a significant feature as many previous works have indicated that commercial shots mostly have high motion content as they try to convey maximum information in minimum possible time.\n",
    "\n",
    "### Frame Difference Distribution\n",
    "\n",
    "The Frame Difference Distribution is the measure of the difference between the current frame and a reference frame, often called \"background image\", or \"background model\". This will assist in measuring the perceived speed at which the frames appear to differentiate. Sudden changes in pixel intensities are grasped by Frame Difference Distribution. Such changes are not registered by optical flow. Thus, Frame Difference Distribution is also computed along with flow magnitude distributions. The researchers obtain the frame difference by averaging absolute frame difference in each of 3 color channels and the distribution is constructed with 32 bins in the range of [0, 255].\n",
    "\n",
    "### Text area distribution\n",
    "\n",
    "The text area distribution is like the text area distribution in that is the measure of the difference between the current text on screen and a reference amount of text. The text distribution feature is obtained by averaging the fraction of text area present in a grid block over all frames of the shot.\n",
    "Bag of Audio Words\n",
    "This attribute is to be removed to reduce the sparseness of the data set.\n",
    "\n",
    "### Bag of Audio Words (4000 bins)\n",
    "\n",
    "The MFCC Bag of Audio Words have been successfully used in several existing speech / audio processing applications. MFCC coefficients along with Delta and Delta-Delta Cepstrum are computed from 150 hours of audio tracks. These coefficients are clustered into 4,000 groups which form the Audio words. Each shot is then represented as a 4,000 Dimensional Bag of Audio Words by forming the normalized histograms of the MFCC's extracted from 20 ms windows with overlap of 10 ms in the shots.\n",
    "\n",
    "###  Edge change Ratio\n",
    "\n",
    "Edge Change Ratio Captures the motion of edges between consecutive frames and is defined as ratio of displaced edge pixels to the total number of edge pixels in a frame. The researchers calculated the mean and variance of the ECR over the entire shot.\n",
    "\n",
    "<a id=\"Section 1.3: Potentially Useful Attribues\"></a>\n",
    "\n",
    "## Section 1.3: Potentially Useful Attribues\n",
    "\n",
    "* A broadcast company code and/or name (there are five broadcast companies in this dataset)\n",
    "* The volume of the audio (commercials tend to be louder in volume than the show)\n",
    "\n",
    "<a id=\"Section 1.4: Columns and Data Types\"></a>\n",
    "\n",
    "## Section 1.4: Columns and Data Types\n",
    "\n",
    "The table below shows the attributes and their data types in tabular format for quick review.\n",
    "\n",
    "NOTE: There are inconsistencies in the column indexing per the readme.txt file - all relating to binning, the Motion Distribution attribute (18-58) should be columns 18-57 leaving column 58 as a 'filler' with an unknown value. Likewise, the Frame Difference Distribution attribute (59-91) should be columns 59-90 leaving column 91 as a 'filler' with an unknown value. The Text Area Distribution attribute (92-122) should be columns 92-121 leaving column 122 as a 'filler with an unknown value. One hint that the indexing is off is the binning attributes ending in an even number rather than an odd number. While the filler values are unknown, they are still included in the dataframes, and, therefore, the models. So while their labels may be a bit unclear, the actual values in those columns are still being used as input into our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Attribute Name                 Columns    Data Types    Type         Notes\n",
      "--  -----------------------------  ---------  ------------  -----------  -------------------------------------\n",
      " 0  Dimension Index                0          integer       Categorical  Target variable\n",
      " 1  Shot Length                    1          integer       Continuous\n",
      " 2  Motion Distribution            2-3        float         Continuous   Mean and Variance\n",
      " 3  Frame Difference Distribution  4-5        float         Continuous   Mean and Variance\n",
      " 4  Short time energy              6-7        float         Continuous   Mean and Variance\n",
      " 5  ZCR                            8-9        float         Continuous   Mean and Variance\n",
      " 6  Spectral Centroid              10-11      float         Continuous   Mean and Variance\n",
      " 7  Spectral Roll off              12-13      float         Continuous   Mean and Variance\n",
      " 8  Spectral Flux                  14-15      float         Continuous   Mean and Variance\n",
      " 9  Fundamental Frequency          16-17      float         Continuous   Mean and Variance\n",
      "10  Motion Distribution            18-57      float         Continuous   40 bins\n",
      "11  Filler                         58         float         Continuous   Unknown value\n",
      "12  Frame Difference Distribution  59-90      float         Continuous   32 bins\n",
      "13  Filler                         91         float         Continuous   Unknown value\n",
      "14  Text area distribution         92-121     float         Continuous   15 bins Mean and 15 bins for variance\n",
      "15  Filler                         122        float         Continuous   Unknown value\n",
      "16  Bag of Audio Words             123-4123   float         Continuous   4,000 bins\n",
      "17  Edge change Ratio              4124-4125  float         Continuous   Mean and Variance\n"
     ]
    }
   ],
   "source": [
    "# We are using a Pandas dataframe to tabulate the data (and provide an simple introduction into Pandas)\n",
    "\n",
    "df_attributes = pd.DataFrame(\n",
    "  data=[\n",
    "    ('Dimension Index','0','integer','Categorical','Target variable'),\n",
    "    ('Shot Length','1','integer','Continuous',''),\n",
    "    ('Motion Distribution','2-3','float','Continuous','Mean and Variance'),\n",
    "    ('Frame Difference Distribution','4-5','float','Continuous','Mean and Variance'),\n",
    "    ('Short time energy','6-7','float','Continuous','Mean and Variance'),\n",
    "    ('ZCR','8-9','float','Continuous','Mean and Variance'),\n",
    "    ('Spectral Centroid','10-11','float','Continuous','Mean and Variance'),\n",
    "    ('Spectral Roll off','12-13','float','Continuous','Mean and Variance'),\n",
    "    ('Spectral Flux','14-15','float','Continuous','Mean and Variance'),\n",
    "    ('Fundamental Frequency','16-17','float','Continuous','Mean and Variance'),\n",
    "    ('Motion Distribution','18-57','float','Continuous','40 bins'),\n",
    "    ('Filler','58', 'float','Continuous','Unknown value'),\n",
    "    ('Frame Difference Distribution','59-90','float','Continuous','32 bins'),\n",
    "    ('Filler','91', 'float','Continuous','Unknown value'),\n",
    "    ('Text area distribution','92-121','float','Continuous','15 bins Mean and 15 bins for variance'),\n",
    "    ('Filler','122', 'float','Continuous','Unknown value'),\n",
    "    ('Bag of Audio Words','123-4123','float','Continuous','4,000 bins'), \n",
    "    ('Edge change Ratio','4124-4125','float','Continuous','Mean and Variance')\n",
    "  ],\n",
    "  columns=[\n",
    "    'Attribute Name','Columns','Data Types', 'Type', 'Notes'\n",
    "  ],\n",
    ")\n",
    "\n",
    "# we will later omit the Bag of Audio Words attribute,\"123-4123\" to reduce the sparcity of the data.\n",
    "# tabulate is used to left justify these string value columns (versus the right-justified default)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(df_attributes, showindex=True, headers=df_attributes.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2: Data Preparation\"></a>\n",
    "\n",
    "# Section 2: Data Preparation\n",
    "\n",
    "This section covers the activities needed to construct the dataset that will be fed into the models. The files for this project  (bbc.txt, cnn.txt, cnnibn.txt, ndtv.txt, and timesnow.txt) can be found at  https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset as a single ZIP file. To eliminate  manual work and streamline file processing, these five files were extracted and put on a team member's website (http://www.shookfamily.org) as follows:\n",
    "\n",
    "http://www.shookfamily.org/data/BBC.txt (17,720 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/CNN.txt (22,545 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/CNNIBN.txt (33,117 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/NDTV.txt (17,051 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/TIMESNOW.txt (39,252 lines)\n",
    "\n",
    "As shown in the cells below, it takes several steps to download the files and process them into the final dataset.\n",
    "\n",
    "The overall goal is to download the files from the internet and load them into an in-memory object. Because these files are stored in the SVM Light format, they are first loaded into a scipy.sparse matrix array object. These sparse matrix arrays are then inspected to eliminate as many columns as possible, and, consequently, reduce the sparseness of the matrix. Once that is accomplished, the scipy.sparse matrix arrays are converted to Pandas DataFrames for faster data processing and input into the accompanying data models.\n",
    "\n",
    "<a id=\"Section 2.1: Download Files\"></a>\n",
    "\n",
    "## Section 2.1: Download Files\n",
    "\n",
    "The first step in this proces is to download the five files from the internet. The data is in a pickled (marshalled / serialized) format used to persist an SVM Light dataset. The SVM Light format is basically an Index : Value pair where the index represents an element in a sparse matrix array and the value associated with that element. For example, a partial record like the following:\n",
    "\n",
    "> 1 1:123 2:1.316440 3:1.516003 ...\n",
    "\n",
    "represents the Y-axis lable followed by the X-Axis values where the first, second, and third elements are a sparse matrix array with the values 123, 1.316440, and 1.516003 (or array[0] == 123, array[1] == 1.316440, and array[2] == 1.516003. The code below downloads each SVM Light file from the internet as a scipy.sparse matrix object and converts this to as two numpy arrays X and Y representing the X axis and the Y axis.\n",
    "\n",
    "<b>Runtime Expectation:</b> It takes about 30 to 60 seconds to download and convert these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading datasets from the internet ...\n",
      "\n",
      "Downloading (as scipy.sparse matrix) ... http://www.shookfamily.org/data/BBC.txt\n",
      "Wall time: 4.38 s\n",
      "Wall time: 7.25 s\n",
      "Wall time: 9.33 s\n",
      "Wall time: 5.66 s\n",
      "Wall time: 20.7 s\n",
      "\n",
      "All files have been downloaded\n",
      "Wall time: 49.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import urllib.request\n",
    "import tempfile\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "url_bbc      = 'http://www.shookfamily.org/data/BBC.txt'\n",
    "url_cnn      = 'http://www.shookfamily.org/data/CNN.txt'\n",
    "url_cnnibn   = 'http://www.shookfamily.org/data/CNNIBN.txt'\n",
    "url_ndtv     = 'http://www.shookfamily.org/data/NDTV.txt'\n",
    "url_timesnow = 'http://www.shookfamily.org/data/TIMESNOW.txt'\n",
    "\n",
    "################################################################################\n",
    "# Download file to a temporary file. Load that file into a scipy.sparse matrix\n",
    "# array, and then return that object to the caller.\n",
    "################################################################################\n",
    "\n",
    "def get_pickled_file(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    text = data.decode('utf-8') # a `str`; this step can't be used if data is binary\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w') as file_handle:\n",
    "        assert text is not None\n",
    "        file_handle.write(text)\n",
    "        filename = file_handle.name\n",
    "\n",
    "        return load_svmlight_file(filename)   # Returns the X axis and  Y axis\n",
    "\n",
    "################################################################################\n",
    "# Dowload files as scipy.sparse matrix arrays\n",
    "################################################################################\n",
    "\n",
    "print('Downloading datasets from the internet ...\\n')\n",
    "print('Downloading (as scipy.sparse matrix) ...', url_bbc)\n",
    "\n",
    "%time X1, y1 = get_pickled_file(url_bbc)\n",
    "%time X2, y2 = get_pickled_file(url_cnn)\n",
    "%time X3, y3 = get_pickled_file(url_cnnibn)\n",
    "%time X4, y4 = get_pickled_file(url_ndtv)\n",
    "%time X5, y5 = get_pickled_file(url_timesnow)\n",
    "\n",
    "print('\\nAll files have been downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.2: Pivot the Y-axis\"></a>\n",
    "\n",
    "## Section 2.2: Pivot the Y-axis\n",
    "\n",
    "The Y-axis variables (y1, y2, y3, y4, y5) are returned from the cell above as arrays in a column-wise orientation:\n",
    "\n",
    "> array([ 1.,  1.,  1., ...,  1.,  1.,  1.])\n",
    "\n",
    "The code below pivots those arrays to a row-wise orientation:\n",
    "\n",
    "> array(  \n",
    "&nbsp;&nbsp;[  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.]  \n",
    "&nbsp;&nbsp;]  \n",
    ")\n",
    "\n",
    "<b>Runtime Expectation:</b> It takes less than a second to run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Y1 = y1[:, None]   # bbc\n",
    "Y2 = y2[:, None]   # cnn\n",
    "Y3 = y3[:, None]   # cnnibn\n",
    "Y4 = y4[:, None]   # ndtv\n",
    "Y5 = y5[:, None]   # timesnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.3: Convert Sparse Matrix Array to an Array\"></a>\n",
    "\n",
    "## Section 2.3: Convert Sparse Matrix Array to an Array\n",
    "\n",
    "The first five cells display some information about each sparse matrix array. The last cell converts those sparse matrix array into a dense array.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<17720x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1813150 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X1  # bbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<22545x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2895841 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X2  # cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<33117x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4189576 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X3  # cnnibn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<17051x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2150834 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X4  # ndtv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<39252x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4992517 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X5  # timesnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 532 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_dense1 = X1.toarray()  # bbc\n",
    "X_dense2 = X2.toarray()  # cnn\n",
    "X_dense3 = X3.toarray()  # cnnibn\n",
    "X_dense4 = X4.toarray()  # ndtv\n",
    "X_dense5 = X5.toarray()  # timesnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.4: Concatenate the Y-axis before the X-axis\"></a>\n",
    "\n",
    "## Section 2.4: Concatenate the Y-axis before the X-axis\n",
    "\n",
    "Now that the Y-axis has been pivoted from a column-wise orientation to a row-wise orientation, we can concatenate the two arrays so the Y-axis is i\n",
    "nserted before the X-axis. This places the Dependent Variable in the first column followed by the Independent Variables.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 10 to 15 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "concat1 = np.hstack((Y1, X_dense1))  # bbc\n",
    "concat2 = np.hstack((Y2, X_dense2))  # cnn\n",
    "concat3 = np.hstack((Y3, X_dense3))  # cnnibn\n",
    "concat4 = np.hstack((Y4, X_dense4))  # ndtv\n",
    "concat5 = np.hstack((Y5, X_dense5))  # timesnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.5: Convert the Arrays into Pandas Dataframes\"></a>\n",
    "\n",
    "## Section 2.5: Convert the Arrays into Pandas Dataframes\n",
    "\n",
    "The following code converts the concatenated dense arrays into Pandas dataframes (to get them into the Pandas ecosystem).\n",
    "\n",
    "### Section 2.5.1: Convert the First Set of Dataframes (no BoWs)\n",
    "\n",
    "The first set of dataframes will be used to model without the Bag of Words.\n",
    "\n",
    "This set of dataframes is consistent with the data preparation, visualization, and modeling in Lab 1 and the MiniLab (where we had deleted the Bag of Words to simplify those projects).\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a second or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17720 22545 33117 17051 39252 129685\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 16.9 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 21.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 31.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 16.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 37.4 MB\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_bbc      = pd.DataFrame(concat1)\n",
    "df_cnn      = pd.DataFrame(concat2)\n",
    "df_cnnibn   = pd.DataFrame(concat3)\n",
    "df_ndtv     = pd.DataFrame(concat4)\n",
    "df_timesnow = pd.DataFrame(concat5)\n",
    "\n",
    "print(len(df_bbc.index), len(df_cnn.index), len(df_cnnibn.index), len(df_ndtv.index), len(df_timesnow.index),\n",
    "    len(df_bbc.index) + len(df_cnn.index) + len(df_cnnibn.index) + len(df_ndtv.index) + len(df_timesnow.index))\n",
    "\n",
    "drop_cols = np.arange(123, 4124)\n",
    "\n",
    "df_bbc      = df_bbc.drop(drop_cols, 1)\n",
    "df_cnn      = df_cnn.drop(drop_cols, 1)\n",
    "df_cnnibn   = df_cnnibn.drop(drop_cols, 1)\n",
    "df_ndtv     = df_ndtv.drop(drop_cols, 1)\n",
    "df_timesnow = df_timesnow.drop(drop_cols, 1)\n",
    "\n",
    "df_bbc.info()\n",
    "df_cnn.info()\n",
    "df_cnnibn.info()\n",
    "df_ndtv.info()\n",
    "df_timesnow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5.2: Convert the Second Set of Dataframes (BoWs)\n",
    "\n",
    "The second set of dataframes will be used to model with the Bag of Words (*_w_bow).\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 10 to 20 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17720 22545 33117 17051 39252 129685\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 541.0 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 688.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 1011.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 520.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 1.2 GB\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_bbc_w_bow      = pd.DataFrame(concat1)   # df_bbc_w_bow (*_with_bag_of_words)\n",
    "df_cnn_w_bow      = pd.DataFrame(concat2)\n",
    "df_cnnibn_w_bow   = pd.DataFrame(concat3)\n",
    "df_ndtv_w_bow     = pd.DataFrame(concat4)\n",
    "df_timesnow_w_bow = pd.DataFrame(concat5)\n",
    "\n",
    "print(len(df_bbc_w_bow.index), len(df_cnn_w_bow.index), len(df_cnnibn_w_bow.index), len(df_ndtv_w_bow.index),\n",
    "    len(df_timesnow_w_bow.index), len(df_bbc.index) + len(df_cnn.index) + len(df_cnnibn.index) + len(df_ndtv.index) + \n",
    "    len(df_timesnow.index))\n",
    "\n",
    "drop_cols = np.append(np.arange(1, 123), np.arange(4124, 4126))\n",
    "\n",
    "df_bbc_w_bow      = df_bbc_w_bow.drop(drop_cols, 1)\n",
    "df_cnn_w_bow      = df_cnn_w_bow.drop(drop_cols, 1)\n",
    "df_cnnibn_w_bow   = df_cnnibn_w_bow.drop(drop_cols, 1)\n",
    "df_ndtv_w_bow     = df_ndtv_w_bow.drop(drop_cols, 1)\n",
    "df_timesnow_w_bow = df_timesnow_w_bow.drop(drop_cols, 1)\n",
    "\n",
    "df_bbc_w_bow.info()\n",
    "df_cnn_w_bow.info()\n",
    "df_cnnibn_w_bow.info()\n",
    "df_ndtv_w_bow.info()\n",
    "df_timesnow_w_bow.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.6: Rename Columns from Integers to Labels\"></a>\n",
    "\n",
    "## Section 2.6: Rename Columns from Integers to Labels\n",
    "\n",
    "### Section 2.6.1: Rename the First Set of Dataframes (no BoWs)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in less than a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dimension Index  Shot Length  Motion Distribution-Mean  \\\n",
      "0              1.0        123.0                   1.31644   \n",
      "\n",
      "   Motion Distribution-Variance  Frame Difference Distribution-Mean  \\\n",
      "0                      1.516003                            5.605905   \n",
      "\n",
      "   Frame Difference Distribution-Variance  Short time energy-Mean  \\\n",
      "0                                 5.34676                0.013233   \n",
      "\n",
      "   Short time energy-Variance  ZCR-Mean  ZCR-Variance  \\\n",
      "0                    0.010729  0.091743      0.050768   \n",
      "\n",
      "              ...              Text area distribution-Bin 9-Variance  \\\n",
      "0             ...                                           0.037647   \n",
      "\n",
      "   Text area distribution-Bin 10-Variance  \\\n",
      "0                                0.006015   \n",
      "\n",
      "   Text area distribution-Bin 11-Variance  \\\n",
      "0                                0.160327   \n",
      "\n",
      "   Text area distribution-Bin 12-Variance  \\\n",
      "0                                0.251688   \n",
      "\n",
      "   Text area distribution-Bin 13-Variance  \\\n",
      "0                                0.176144   \n",
      "\n",
      "   Text area distribution-Bin 14-Variance  \\\n",
      "0                                     0.0   \n",
      "\n",
      "   Text area distribution-Bin 15-Variance  \\\n",
      "0                                     0.0   \n",
      "\n",
      "   Attribute 122 should be Bin 15-Variance  Edge change Ratio-Mean  \\\n",
      "0                                      0.0                0.422334   \n",
      "\n",
      "   Edge change Ratio-Variance  \n",
      "0                    0.663918  \n",
      "\n",
      "[1 rows x 125 columns]\n",
      "Wall time: 20 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ren_cols = np.array([\n",
    "    'Dimension Index',\n",
    "    'Shot Length',\n",
    "    'Motion Distribution-Mean', 'Motion Distribution-Variance',\n",
    "    'Frame Difference Distribution-Mean', 'Frame Difference Distribution-Variance',\n",
    "    'Short time energy-Mean', 'Short time energy-Variance',\n",
    "    'ZCR-Mean', 'ZCR-Variance',\n",
    "    'Spectral Centroid-Mean', 'Spectral Centroid-Variance',\n",
    "    'Spectral Roll off-Mean', 'Spectral Roll off-Variance',\n",
    "    'Spectral Flux-Mean', 'Spectral Flux-Variance',\n",
    "    'Fundamental Frequency-Mean', 'Fundamental Frequency-Variance',\n",
    "    'Motion Distribution-Bin 1', 'Motion Distribution-Bin 2', 'Motion Distribution-Bin 3', 'Motion Distribution-Bin 4',\n",
    "    'Motion Distribution-Bin 5', 'Motion Distribution-Bin 6', 'Motion Distribution-Bin 7', 'Motion Distribution-Bin 8',\n",
    "    'Motion Distribution-Bin 9', 'Motion Distribution-Bin 10', 'Motion Distribution-Bin 11', 'Motion Distribution-Bin 12',\n",
    "    'Motion Distribution-Bin 13', 'Motion Distribution-Bin 14', 'Motion Distribution-Bin 15', 'Motion Distribution-Bin 16',\n",
    "    'Motion Distribution-Bin 17', 'Motion Distribution-Bin 18', 'Motion Distribution-Bin 19', 'Motion Distribution-Bin 20',\n",
    "    'Motion Distribution-Bin 21', 'Motion Distribution-Bin 22', 'Motion Distribution-Bin 23', 'Motion Distribution-Bin 24',\n",
    "    'Motion Distribution-Bin 25', 'Motion Distribution-Bin 26', 'Motion Distribution-Bin 27', 'Motion Distribution-Bin 28',\n",
    "    'Motion Distribution-Bin 29', 'Motion Distribution-Bin 30', 'Motion Distribution-Bin 31', 'Motion Distribution-Bin 32',\n",
    "    'Motion Distribution-Bin 33', 'Motion Distribution-Bin 34', 'Motion Distribution-Bin 35', 'Motion Distribution-Bin 36',\n",
    "    'Motion Distribution-Bin 37', 'Motion Distribution-Bin 38', 'Motion Distribution-Bin 39', 'Motion Distribution-Bin 40',\n",
    "    'Filler 1',\n",
    "    'Frame Difference Distribution-Bin 1', 'Frame Difference Distribution-Bin 2',\n",
    "    'Frame Difference Distribution-Bin 3', 'Frame Difference Distribution-Bin 4',\n",
    "    'Frame Difference Distribution-Bin 5', 'Frame Difference Distribution-Bin 6',\n",
    "    'Frame Difference Distribution-Bin 7', 'Frame Difference Distribution-Bin 8',\n",
    "    'Frame Difference Distribution-Bin 9', 'Frame Difference Distribution-Bin 10',\n",
    "    'Frame Difference Distribution-Bin 11', 'Frame Difference Distribution-Bin 12',\n",
    "    'Frame Difference Distribution-Bin 13', 'Frame Difference Distribution-Bin 14',\n",
    "    'Frame Difference Distribution-Bin 15', 'Frame Difference Distribution-Bin 16',\n",
    "    'Frame Difference Distribution-Bin 17', 'Frame Difference Distribution-Bin 18',\n",
    "    'Frame Difference Distribution-Bin 19', 'Frame Difference Distribution-Bin 20',\n",
    "    'Frame Difference Distribution-Bin 21', 'Frame Difference Distribution-Bin 22',\n",
    "    'Frame Difference Distribution-Bin 23', 'Frame Difference Distribution-Bin 24',\n",
    "    'Frame Difference Distribution-Bin 25', 'Frame Difference Distribution-Bin 26',\n",
    "    'Frame Difference Distribution-Bin 27', 'Frame Difference Distribution-Bin 28',\n",
    "    'Frame Difference Distribution-Bin 29', 'Frame Difference Distribution-Bin 30',\n",
    "    'Frame Difference Distribution-Bin 31', 'Frame Difference Distribution-Bin 32',\n",
    "    'Filler 2',\n",
    "    'Text area distribution-Bin 1-Mean', 'Text area distribution-Bin 2-Mean',\n",
    "    'Text area distribution-Bin 3-Mean', 'Text area distribution-Bin 4-Mean',\n",
    "    'Text area distribution-Bin 5-Mean', 'Text area distribution-Bin 6-Mean',\n",
    "    'Text area distribution-Bin 7-Mean', 'Text area distribution-Bin 8-Mean',\n",
    "    'Text area distribution-Bin 9-Mean', 'Text area distribution-Bin 10-Mean',\n",
    "    'Text area distribution-Bin 11-Mean', 'Text area distribution-Bin 12-Mean',\n",
    "    'Text area distribution-Bin 13-Mean', 'Text area distribution-Bin 14-Mean',\n",
    "    'Text area distribution-Bin 15-Mean',\n",
    "    'Text area distribution-Bin 1-Variance', 'Text area distribution-Bin 2-Variance',\n",
    "    'Text area distribution-Bin 3-Variance', 'Text area distribution-Bin 4-Variance',\n",
    "    'Text area distribution-Bin 5-Variance', 'Text area distribution-Bin 6-Variance',\n",
    "    'Text area distribution-Bin 7-Variance', 'Text area distribution-Bin 8-Variance',\n",
    "    'Text area distribution-Bin 9-Variance', 'Text area distribution-Bin 10-Variance',\n",
    "    'Text area distribution-Bin 11-Variance', 'Text area distribution-Bin 12-Variance',\n",
    "    'Text area distribution-Bin 13-Variance', 'Text area distribution-Bin 14-Variance',\n",
    "    'Text area distribution-Bin 15-Variance', 'Attribute 122 should be Bin 15-Variance',\n",
    "    'Edge change Ratio-Mean', 'Edge change Ratio-Variance'\n",
    "])\n",
    "    \n",
    "df_bbc.columns = ren_cols\n",
    "df_cnn.columns = ren_cols\n",
    "df_cnnibn.columns = ren_cols\n",
    "df_ndtv.columns = ren_cols\n",
    "df_timesnow.columns = ren_cols\n",
    "\n",
    "print(df_bbc.iloc[0:1:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.6.2: Rename the Second Set of Dataframes (BoWs)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in less than a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4002\n",
      "['Dimension Index' 'BoW 1' 'BoW 2' ..., 'BoW 3999' 'BoW 4000' 'BoW 4001']\n",
      "   Dimension Index     BoW 1  BoW 2  BoW 3  BoW 4  BoW 5  BoW 6  BoW 7  BoW 8  \\\n",
      "0              1.0  0.006356    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   BoW 9    ...     BoW 3992  BoW 3993  BoW 3994  BoW 3995  BoW 3996  \\\n",
      "0    0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   BoW 3997  BoW 3998  BoW 3999  BoW 4000  BoW 4001  \n",
      "0       0.0       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[1 rows x 4002 columns]\n",
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ren_cols = np.array(['Dimension Index'])\n",
    "\n",
    "print(ren_cols.size)\n",
    "\n",
    "for i in np.arange(1, 4002):\n",
    "    ren_cols = np.append(ren_cols, 'BoW ' + str(i))\n",
    "\n",
    "print(ren_cols.size)\n",
    "print(ren_cols)\n",
    "\n",
    "df_bbc_w_bow.columns = ren_cols\n",
    "df_cnn_w_bow.columns = ren_cols\n",
    "df_cnnibn_w_bow.columns = ren_cols\n",
    "df_ndtv_w_bow.columns = ren_cols\n",
    "df_timesnow_w_bow.columns = ren_cols\n",
    "\n",
    "print(df_bbc_w_bow.iloc[0:1:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.7: Inspecting Missing Values\"></a>\n",
    "\n",
    "## Section 2.7: Inspecting Missing Values\n",
    "\n",
    "As shown is the output above, 120 columns are left in the dataframe. 4,005 columns were deleted after eliminating the Bag of Words (4,000 columns) and the five columns (88, 89, 120, 121, 123) with all zero values.\n",
    "\n",
    "###  Section 2.7.1: Display Table of Missing Values\n",
    "\n",
    "The code below displays columns with SOME missing values (versus ALL missing values).\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dimension Index</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shot Length</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Mean</th>\n",
       "      <td>4014</td>\n",
       "      <td>22.652370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Variance</th>\n",
       "      <td>4014</td>\n",
       "      <td>22.652370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short time energy-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short time energy-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZCR-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZCR-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Centroid-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Centroid-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Roll off-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Roll off-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Flux-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Flux-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fundamental Frequency-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fundamental Frequency-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 1</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 2</th>\n",
       "      <td>4014</td>\n",
       "      <td>22.652370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 3</th>\n",
       "      <td>4015</td>\n",
       "      <td>22.658014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 4</th>\n",
       "      <td>4015</td>\n",
       "      <td>22.658014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 5</th>\n",
       "      <td>4031</td>\n",
       "      <td>22.748307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 6</th>\n",
       "      <td>4057</td>\n",
       "      <td>22.895034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 7</th>\n",
       "      <td>4083</td>\n",
       "      <td>23.041761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 8</th>\n",
       "      <td>4116</td>\n",
       "      <td>23.227991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 9</th>\n",
       "      <td>4169</td>\n",
       "      <td>23.527088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 10</th>\n",
       "      <td>4226</td>\n",
       "      <td>23.848758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 11</th>\n",
       "      <td>4263</td>\n",
       "      <td>24.057562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 12</th>\n",
       "      <td>4311</td>\n",
       "      <td>24.328442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 4-Mean</th>\n",
       "      <td>9514</td>\n",
       "      <td>53.690745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 5-Mean</th>\n",
       "      <td>9002</td>\n",
       "      <td>50.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 6-Mean</th>\n",
       "      <td>8201</td>\n",
       "      <td>46.281038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 7-Mean</th>\n",
       "      <td>8773</td>\n",
       "      <td>49.509029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 8-Mean</th>\n",
       "      <td>7572</td>\n",
       "      <td>42.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 9-Mean</th>\n",
       "      <td>7270</td>\n",
       "      <td>41.027088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 10-Mean</th>\n",
       "      <td>8188</td>\n",
       "      <td>46.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 11-Mean</th>\n",
       "      <td>4712</td>\n",
       "      <td>26.591422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 12-Mean</th>\n",
       "      <td>4808</td>\n",
       "      <td>27.133183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 13-Mean</th>\n",
       "      <td>5838</td>\n",
       "      <td>32.945824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 14-Mean</th>\n",
       "      <td>11427</td>\n",
       "      <td>64.486456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 15-Mean</th>\n",
       "      <td>11109</td>\n",
       "      <td>62.691874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 1-Variance</th>\n",
       "      <td>9232</td>\n",
       "      <td>52.099323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 2-Variance</th>\n",
       "      <td>9807</td>\n",
       "      <td>55.344244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 3-Variance</th>\n",
       "      <td>9196</td>\n",
       "      <td>51.896163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 4-Variance</th>\n",
       "      <td>9514</td>\n",
       "      <td>53.690745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 5-Variance</th>\n",
       "      <td>9002</td>\n",
       "      <td>50.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 6-Variance</th>\n",
       "      <td>8201</td>\n",
       "      <td>46.281038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 7-Variance</th>\n",
       "      <td>8773</td>\n",
       "      <td>49.509029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 8-Variance</th>\n",
       "      <td>7572</td>\n",
       "      <td>42.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 9-Variance</th>\n",
       "      <td>7270</td>\n",
       "      <td>41.027088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 10-Variance</th>\n",
       "      <td>8188</td>\n",
       "      <td>46.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 11-Variance</th>\n",
       "      <td>4712</td>\n",
       "      <td>26.591422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 12-Variance</th>\n",
       "      <td>4808</td>\n",
       "      <td>27.133183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 13-Variance</th>\n",
       "      <td>5838</td>\n",
       "      <td>32.945824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 14-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 15-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute 122 should be Bin 15-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edge change Ratio-Mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edge change Ratio-Variance</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Missing Values  % of Total Values\n",
       "Dimension Index                                       0           0.000000\n",
       "Shot Length                                           0           0.000000\n",
       "Motion Distribution-Mean                           4014          22.652370\n",
       "Motion Distribution-Variance                       4014          22.652370\n",
       "Frame Difference Distribution-Mean                 4013          22.646727\n",
       "Frame Difference Distribution-Variance             4013          22.646727\n",
       "Short time energy-Mean                             4013          22.646727\n",
       "Short time energy-Variance                         4013          22.646727\n",
       "ZCR-Mean                                           4013          22.646727\n",
       "ZCR-Variance                                       4013          22.646727\n",
       "Spectral Centroid-Mean                             4013          22.646727\n",
       "Spectral Centroid-Variance                         4013          22.646727\n",
       "Spectral Roll off-Mean                             4013          22.646727\n",
       "Spectral Roll off-Variance                         4013          22.646727\n",
       "Spectral Flux-Mean                                 4013          22.646727\n",
       "Spectral Flux-Variance                             4013          22.646727\n",
       "Fundamental Frequency-Mean                         4013          22.646727\n",
       "Fundamental Frequency-Variance                     4013          22.646727\n",
       "Motion Distribution-Bin 1                          4013          22.646727\n",
       "Motion Distribution-Bin 2                          4014          22.652370\n",
       "Motion Distribution-Bin 3                          4015          22.658014\n",
       "Motion Distribution-Bin 4                          4015          22.658014\n",
       "Motion Distribution-Bin 5                          4031          22.748307\n",
       "Motion Distribution-Bin 6                          4057          22.895034\n",
       "Motion Distribution-Bin 7                          4083          23.041761\n",
       "Motion Distribution-Bin 8                          4116          23.227991\n",
       "Motion Distribution-Bin 9                          4169          23.527088\n",
       "Motion Distribution-Bin 10                         4226          23.848758\n",
       "Motion Distribution-Bin 11                         4263          24.057562\n",
       "Motion Distribution-Bin 12                         4311          24.328442\n",
       "...                                                 ...                ...\n",
       "Text area distribution-Bin 4-Mean                  9514          53.690745\n",
       "Text area distribution-Bin 5-Mean                  9002          50.801354\n",
       "Text area distribution-Bin 6-Mean                  8201          46.281038\n",
       "Text area distribution-Bin 7-Mean                  8773          49.509029\n",
       "Text area distribution-Bin 8-Mean                  7572          42.731377\n",
       "Text area distribution-Bin 9-Mean                  7270          41.027088\n",
       "Text area distribution-Bin 10-Mean                 8188          46.207675\n",
       "Text area distribution-Bin 11-Mean                 4712          26.591422\n",
       "Text area distribution-Bin 12-Mean                 4808          27.133183\n",
       "Text area distribution-Bin 13-Mean                 5838          32.945824\n",
       "Text area distribution-Bin 14-Mean                11427          64.486456\n",
       "Text area distribution-Bin 15-Mean                11109          62.691874\n",
       "Text area distribution-Bin 1-Variance              9232          52.099323\n",
       "Text area distribution-Bin 2-Variance              9807          55.344244\n",
       "Text area distribution-Bin 3-Variance              9196          51.896163\n",
       "Text area distribution-Bin 4-Variance              9514          53.690745\n",
       "Text area distribution-Bin 5-Variance              9002          50.801354\n",
       "Text area distribution-Bin 6-Variance              8201          46.281038\n",
       "Text area distribution-Bin 7-Variance              8773          49.509029\n",
       "Text area distribution-Bin 8-Variance              7572          42.731377\n",
       "Text area distribution-Bin 9-Variance              7270          41.027088\n",
       "Text area distribution-Bin 10-Variance             8188          46.207675\n",
       "Text area distribution-Bin 11-Variance             4712          26.591422\n",
       "Text area distribution-Bin 12-Variance             4808          27.133183\n",
       "Text area distribution-Bin 13-Variance             5838          32.945824\n",
       "Text area distribution-Bin 14-Variance            17720         100.000000\n",
       "Text area distribution-Bin 15-Variance            17720         100.000000\n",
       "Attribute 122 should be Bin 15-Variance           17720         100.000000\n",
       "Edge change Ratio-Mean                                0           0.000000\n",
       "Edge change Ratio-Variance                            0           0.000000\n",
       "\n",
       "[125 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percentage_of_zeros_table(df):\n",
    "    numberOf_nonzeros = df.astype(bool).sum(axis=0)\n",
    "    NumberOf_Zeros = df.count()-numberOf_nonzeros\n",
    "    percentOf_Zeros=NumberOf_Zeros / df.count() * 100\n",
    "    table1 = pd.concat([NumberOf_Zeros, percentOf_Zeros], axis=1)\n",
    "    table2 = table1.rename(columns={0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    return table2\n",
    "\n",
    "df_missing_values_table1 = percentage_of_zeros_table(df_bbc)\n",
    "df_missing_values_table2 = percentage_of_zeros_table(df_cnn)\n",
    "df_missing_values_table3 = percentage_of_zeros_table(df_cnnibn)\n",
    "df_missing_values_table4 = percentage_of_zeros_table(df_ndtv)\n",
    "df_missing_values_table5 = percentage_of_zeros_table(df_timesnow)\n",
    "\n",
    "df_missing_values_table1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.7.2: View Missing Values via a Threshold (40%)\n",
    "\n",
    "The code below displays columns having over 40% of its values as zero.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 39</th>\n",
       "      <td>7221</td>\n",
       "      <td>40.750564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 40</th>\n",
       "      <td>7330</td>\n",
       "      <td>41.365688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 26</th>\n",
       "      <td>8214</td>\n",
       "      <td>46.354402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 27</th>\n",
       "      <td>10460</td>\n",
       "      <td>59.029345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 28</th>\n",
       "      <td>13404</td>\n",
       "      <td>75.643341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 29</th>\n",
       "      <td>17650</td>\n",
       "      <td>99.604966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 30</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 31</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 32</th>\n",
       "      <td>11427</td>\n",
       "      <td>64.486456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filler 2</th>\n",
       "      <td>11109</td>\n",
       "      <td>62.691874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 1-Mean</th>\n",
       "      <td>9232</td>\n",
       "      <td>52.099323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 2-Mean</th>\n",
       "      <td>9807</td>\n",
       "      <td>55.344244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 3-Mean</th>\n",
       "      <td>9197</td>\n",
       "      <td>51.901806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 4-Mean</th>\n",
       "      <td>9514</td>\n",
       "      <td>53.690745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 5-Mean</th>\n",
       "      <td>9002</td>\n",
       "      <td>50.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 6-Mean</th>\n",
       "      <td>8201</td>\n",
       "      <td>46.281038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 7-Mean</th>\n",
       "      <td>8773</td>\n",
       "      <td>49.509029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 8-Mean</th>\n",
       "      <td>7572</td>\n",
       "      <td>42.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 9-Mean</th>\n",
       "      <td>7270</td>\n",
       "      <td>41.027088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 10-Mean</th>\n",
       "      <td>8188</td>\n",
       "      <td>46.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 14-Mean</th>\n",
       "      <td>11427</td>\n",
       "      <td>64.486456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 15-Mean</th>\n",
       "      <td>11109</td>\n",
       "      <td>62.691874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 1-Variance</th>\n",
       "      <td>9232</td>\n",
       "      <td>52.099323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 2-Variance</th>\n",
       "      <td>9807</td>\n",
       "      <td>55.344244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 3-Variance</th>\n",
       "      <td>9196</td>\n",
       "      <td>51.896163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 4-Variance</th>\n",
       "      <td>9514</td>\n",
       "      <td>53.690745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 5-Variance</th>\n",
       "      <td>9002</td>\n",
       "      <td>50.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 6-Variance</th>\n",
       "      <td>8201</td>\n",
       "      <td>46.281038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 7-Variance</th>\n",
       "      <td>8773</td>\n",
       "      <td>49.509029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 8-Variance</th>\n",
       "      <td>7572</td>\n",
       "      <td>42.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 9-Variance</th>\n",
       "      <td>7270</td>\n",
       "      <td>41.027088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 10-Variance</th>\n",
       "      <td>8188</td>\n",
       "      <td>46.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 14-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 15-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute 122 should be Bin 15-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Missing Values  % of Total Values\n",
       "Motion Distribution-Bin 39                         7221          40.750564\n",
       "Motion Distribution-Bin 40                         7330          41.365688\n",
       "Frame Difference Distribution-Bin 26               8214          46.354402\n",
       "Frame Difference Distribution-Bin 27              10460          59.029345\n",
       "Frame Difference Distribution-Bin 28              13404          75.643341\n",
       "Frame Difference Distribution-Bin 29              17650          99.604966\n",
       "Frame Difference Distribution-Bin 30              17720         100.000000\n",
       "Frame Difference Distribution-Bin 31              17720         100.000000\n",
       "Frame Difference Distribution-Bin 32              11427          64.486456\n",
       "Filler 2                                          11109          62.691874\n",
       "Text area distribution-Bin 1-Mean                  9232          52.099323\n",
       "Text area distribution-Bin 2-Mean                  9807          55.344244\n",
       "Text area distribution-Bin 3-Mean                  9197          51.901806\n",
       "Text area distribution-Bin 4-Mean                  9514          53.690745\n",
       "Text area distribution-Bin 5-Mean                  9002          50.801354\n",
       "Text area distribution-Bin 6-Mean                  8201          46.281038\n",
       "Text area distribution-Bin 7-Mean                  8773          49.509029\n",
       "Text area distribution-Bin 8-Mean                  7572          42.731377\n",
       "Text area distribution-Bin 9-Mean                  7270          41.027088\n",
       "Text area distribution-Bin 10-Mean                 8188          46.207675\n",
       "Text area distribution-Bin 14-Mean                11427          64.486456\n",
       "Text area distribution-Bin 15-Mean                11109          62.691874\n",
       "Text area distribution-Bin 1-Variance              9232          52.099323\n",
       "Text area distribution-Bin 2-Variance              9807          55.344244\n",
       "Text area distribution-Bin 3-Variance              9196          51.896163\n",
       "Text area distribution-Bin 4-Variance              9514          53.690745\n",
       "Text area distribution-Bin 5-Variance              9002          50.801354\n",
       "Text area distribution-Bin 6-Variance              8201          46.281038\n",
       "Text area distribution-Bin 7-Variance              8773          49.509029\n",
       "Text area distribution-Bin 8-Variance              7572          42.731377\n",
       "Text area distribution-Bin 9-Variance              7270          41.027088\n",
       "Text area distribution-Bin 10-Variance             8188          46.207675\n",
       "Text area distribution-Bin 14-Variance            17720         100.000000\n",
       "Text area distribution-Bin 15-Variance            17720         100.000000\n",
       "Attribute 122 should be Bin 15-Variance           17720         100.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing_values_table1 = df_missing_values_table1[(df_missing_values_table1['% of Total Values'] > 40)]\n",
    "\n",
    "df_missing_values_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.7.3: : Drop Columns with a High Ratio of Missing Values\n",
    "\n",
    "The code below drops column 87, which has about 90% of its values as zero.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Drop column 87 in each of the individual datasets\n",
    "\n",
    "#df_bbc      = df_bbc.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "#df_cnn      = df_cnn.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "#df_cnnibn   = df_cnnibn.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "#df_ndtv     = df_ndtv.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "#df_timesnow = df_timesnow.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "\n",
    "#df_bbc.info()\n",
    "#df_cnn.info()\n",
    "#df_cnnibn.info()\n",
    "#df_ndtv.info()\n",
    "#df_timesnow.info()\n",
    "\n",
    "# The code below should delete 1 columns (87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.8: Concatenate the Five Pandas Dataframes\"></a>\n",
    "\n",
    "## Section 2.8: Concatenate the Five Pandas Dataframes\n",
    "\n",
    "This step concatenates the five Pandas dataframes into the final dataframe.\n",
    "\n",
    "### Section 2.8.1:  Concatenate the First Set of Dataframes (no BoWs)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in less than a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 129685 entries, 0 to 39251\n",
      "Columns: 125 entries, Dimension Index to Edge change Ratio-Variance\n",
      "dtypes: float64(125)\n",
      "memory usage: 124.7 MB\n",
      "Wall time: 71 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_final = pd.concat([df_bbc, df_cnn, df_cnnibn, df_ndtv, df_timesnow])\n",
    "\n",
    "df_final.name = 'TV News Channel Commercial Detection'\n",
    "\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.8.2:  Concatenate the Second Set of Dataframes (BoWs)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 10 to 20 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 129685 entries, 0 to 39251\n",
      "Columns: 4002 entries, Dimension Index to BoW 4001\n",
      "dtypes: float64(4002)\n",
      "memory usage: 3.9 GB\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_final_w_bow = pd.concat([df_bbc_w_bow, df_cnn_w_bow, df_cnnibn_w_bow, df_ndtv_w_bow, df_timesnow_w_bow])\n",
    "\n",
    "df_final_w_bow.name = 'TV News Channel Commercial Detection'\n",
    "\n",
    "df_final_w_bow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 3: Visualizing the Data\"></a>\n",
    "\n",
    "# Section 3: Visualizing the Data \n",
    "\n",
    "## Step 14: Attributes: Pair Plots\n",
    "\n",
    "The code below creates a pair plot for each of the non-binned attributes (columns 0 - 18 and 4124-4125). \n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about <b>10 to 15 minutes</b>.\n",
    "\n",
    "<b>Note:</b> The code is wrapped in a function to allow this long-running cell to be commented or uncommented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import seaborn as sns\n",
    "\n",
    "def create_pair_plots():\n",
    "    for i in range(0, 19):\n",
    "        sns.pairplot(df_concat[[cols[i], cols[i+1], cols[i+2], cols[i+4], cols[i+6], cols[i+8], cols[i+10]]])\n",
    "\n",
    "create_pair_plots()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Attributes: Box Plots\n",
    "\n",
    "The code below creates box plots for all non-binned attributes.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following three cells run in about 5 to 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Box Plot: Attribute 1 - Shot Length\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6.7, 3))\n",
    "\n",
    "axes = df_concat.boxplot(column=cols[1:2], by='Dimension Index', patch_artist=True, ax=ax)\n",
    "\n",
    "axes.set_xlabel('Non-commercial vs. Commercial')   # Non-commericial == -1, Commercial == +1\n",
    "\n",
    "plt.subplots_adjust(top=1.5)\n",
    "plt.suptitle('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Box Plot: Attributes 2-18 - Motion Distribution-Mean to Fundamental Frequency-Variance\n",
    "\n",
    "fig, ax = plt.subplots(8, 2, figsize=(15, 26))\n",
    "\n",
    "axes = df_concat.boxplot(column=cols[2:18], by='Dimension Index', patch_artist=True, ax=ax)\n",
    "\n",
    "for i in axes:\n",
    "    i.set_xlabel('Non-commercial vs. Commercial')   # Non-commericial == -1, Commercial == +1\n",
    "\n",
    "plt.subplots_adjust(top=1.5)\n",
    "plt.suptitle('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Box Plot: Attributes 4124-4125 - Edge change Ratio-Mean to Edge change Ratio-Variance\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "axes = df_concat.boxplot(column=cols[122:124], by='Dimension Index', patch_artist=True, ax=ax)\n",
    "\n",
    "for i in axes:\n",
    "    i.set_xlabel('Non-commercial vs. Commercial')   # Non-commericial == -1, Commercial == +1\n",
    "\n",
    "plt.subplots_adjust(top=1.5)\n",
    "plt.suptitle(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: Attributes: Hexbin Plots\n",
    "\n",
    "The hex bin plots below compare the relationship between the different news sources. The charts visualize the linear relationship that all of the news networks have with the means. They will also help identify outliers.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20,12))\n",
    "\n",
    "# Plot all five datasets / broadcast\n",
    "\n",
    "df_concat.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='All Five Networks',ax=ax[0,0])\n",
    "\n",
    "# Plot each dataset / broadcast\n",
    "\n",
    "df_bbc.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='BBC',ax=ax[0,1])\n",
    "df_cnn.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='CNN',ax=ax[0,2])\n",
    "df_cnnibn.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='CNNIBN',ax=ax[1,0])\n",
    "df_ndtv.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='NDTV',ax=ax[1,1])\n",
    "df_timesnow.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='TIMESNOW',ax=ax[1,2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16a: Attributes: Hexbin Plots\n",
    "\n",
    "The plots below compare multible attributes in the Commercial and Non-Commercial datasets. This shows a true distinction between the two classes and will help demonstrate if it is possible to distinguish between commercial and non-commercial with the data at hand.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "df_commercial.plot('Shot Length','Motion Distribution-Mean', kind='hexbin', gridsize=30,\n",
    "    title='Attribute: Commercial Shot Length', ax=axs[0])\n",
    "df_non_commercial.plot('Shot Length','Motion Distribution-Mean', kind='hexbin', gridsize=30,\n",
    "    title='Attribute: Non-Commercial Shot Length', ax=axs[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16b: Attributes: Hexbin Plots (cont.)\n",
    "\n",
    "The Shot Length of the Commercial and Non-Commercial seams to be close in time. This is consistant with modern tv shows and film making where typical shot lengths last for only a few seconds.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "df_non_commercial.plot('Motion Distribution-Bin 1', 'Attribute 58 should be Bin 40', kind='hexbin', gridsize=30,\n",
    "    title='Attribute: Non-Commercial Motion Distribution', ax=axs[0])\n",
    "df_commercial.plot('Motion Distribution-Bin 1', 'Attribute 58 should be Bin 40', kind='hexbin', gridsize=30,\n",
    "    title='Attribute: Commercial Motion Distribution', ax=axs[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16c: Attributes: Hexbin Plots (cont.)\n",
    "\n",
    "From the hexbin plots below the non-commercial and commercial difference distribution are simular with the non-commerical having a distinct grouping at zero. Further analysis is needed to discover the meaning of this feature in the data which be outliers.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "df_non_commercial.plot('Frame Difference Distribution-Bin 1', 'Attribute 91 should be Bin 32', kind='hexbin', gridsize=30,\n",
    "    title='Attribute: Non-Commercial Frame Difference Distribution', ax=axs[0])\n",
    "df_commercial.plot('Frame Difference Distribution-Bin 1', 'Attribute 91 should be Bin 32', kind='hexbin', gridsize=30,\n",
    "    title = 'Attribute: Commercial Frame Difference Distribution', ax=axs[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16d: Attributes: Hexbin Plots (cont.)\n",
    "\n",
    "The comercial and non-commercial  ZCR (Zero Crossing Rate), the rate of sign-changes along a signal with the non-commerical having a distinct grouing at zero. Further analysis is needed to discover the meanign of this feature in the data.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "df_non_commercial.plot('ZCR-Mean', 'ZCR-Variance', kind='hexbin', gridsize=30,\n",
    "    title = 'Attribute: Non-Commercial ZCR', ax=axs[0])\n",
    "df_commercial.plot('ZCR-Mean', 'ZCR-Variance', kind='hexbin', gridsize=30,\n",
    "    title = 'Attribute: Commercial ZCR', ax=axs[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16e: Attributes: Hexbin Plots (cont.)\n",
    "\n",
    "The hexbin plots from the Commercial and Non-Commercial plots below  demenstrate a simular positive linear relationship with the non-commerical having the more distinct linear relationship.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "df_non_commercial.plot('Spectral Flux-Mean', 'Spectral Flux-Variance', kind='hexbin', gridsize=30,\n",
    "    title = 'Attribute: Non-Commercial Spectral Flux', ax=axs[0])\n",
    "df_commercial.plot('Spectral Flux-Mean', 'Spectral Flux-Variance', kind='hexbin', gridsize=30,\n",
    "    title = 'Attribute: Commercial Spectral Flux', ax=axs[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "The code below creates and X-array of non-binned attributes and a Y-array of the target (Dimension Index: Commercial (+1) or Non-commercial (-1)). The X-array is then scaled and the PCA algorithm is executed against that scaled array. The components array is then concatenated with the target array and converted into a Pandas dataset for further manipulation.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x = df_concat.loc[:, cols[1:19]].values\n",
    "y = df_concat.loc[:,['Dimension Index']].values\n",
    "\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "pca = PCA(n_components=18)\n",
    "\n",
    "components = pca.fit_transform(x)\n",
    "\n",
    "col_names = ['Dimension Index','PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12','PC13','PC14',\n",
    "    'PC15','PC16','PC17','PC18']\n",
    "\n",
    "df_pca = pd.DataFrame(np.hstack((y, components)), columns=col_names)\n",
    "\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from pylab import rcParams\n",
    "\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sb.heatmap(df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output in the cells above, we can probably use the attributes associated with principal components PC1 ... PC5 (since they represent about 80% of the data).\n",
    "\n",
    "# Observations and Analysis\n",
    "\n",
    "## Data Quality\n",
    "\n",
    "Explain any missing values, duplicate data, and outliers. Are those mistakes? How do you deal with these problems? Give justifications for your methods.\n",
    "\n",
    "> >While we were able to produce Pair Plots and Box Plots in addition to the Hex Bin Plots, we are still trying to understand what these plots really mean. It appears most of the Box Plots have the same median. The Box Plot for Shot Length has significant outliers (whiskers).\n",
    "\n",
    "<a id=\"Section 4: Modeling\"></a>\n",
    "\n",
    "# Section 4: Modeling \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
