{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "# Lab 2 - Classification\n",
    "\n",
    "Team: Frank Sclafani, Jan Shook, and Leticia Valadez\n",
    "\n",
    "> VERSION: Updated by Jan\n",
    "           * Added a linear regression that works ... left the old LR at the bottom that didn't work\n",
    "           * baseline for Leticia and Jan to work on together\n",
    "\n",
    "\n",
    "## TV News Channel Commercial Detection\n",
    "\n",
    "Our team selected this dataset for two reasons: 1) It has a large number of instances (129,685, which is greater than the requirement of at least 30,000) and enough attributes (14, which is greater than the requirement of at least 10), and 2) It looks like an interesting dataset (detecting commercials). Initial questions of interest are how do you detect commercials from this data? Can a model be trained to detect and skip (or remove) commercials? If so, would this solution be robust enough for commercial products like TiVo?\n",
    "\n",
    "This dataset is from the UCI Machine Learning website (https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset). It consists of popular audio-visual features of video shots extracted from 150 hours of TV news broadcast of 3 Indian and 2 international news channels (30 Hours each). In the readme accompanying the data, the authors describe the potential benefits of this data as follows:\n",
    "\n",
    "> Automatic identification of commercial blocks in news videos finds a lot of applications in the domain of television broadcast analysis and monitoring. Commercials occupy almost 40-60% of total air time. Manual segmentation of commercials from thousands of TV news channels is time consuming, and economically infeasible hence prompts the need for machine learning based Method. Classifying TV News commercials is a semantic video classification problem. TV News commercials on particular news channel are combinations of video shots uniquely characterized by audio-visual presentation. Hence various audio visual features extracted from video shots are widely used for TV commercial classification. Indian News channels do not follow any particular news presentation format, have large variability and dynamic nature presenting a challenging machine learning problem. Features from 150 Hours of broadcast news videos from 5 different (3 Indian and 2 International News channels) news channels. Viz. CNNIBN, NDTV 24X7, TIMESNOW, BBC and CNN are presented in this dataset. Videos are recorded at resolution of 720 X 576 at 25 fps using a DVR and set top box. 3 Indian channels are recorded concurrently while 2 International are recorded together. Feature file preserves the order of occurrence of shots.\n",
    "\n",
    "### Objective: Classify Video Attributes as Commercial or Non-commercial\n",
    "\n",
    "This dataset has already been classified as commercial (+1) or non-commercial (-1) in the Dimension Index attribute. Hence, in subsequent analysis, we will be able to train and compare our data models against the target variable that has already created to determine the effectiveness of the model.\n",
    "\n",
    "### Techniques Applied in this Project\n",
    "\n",
    "#### Data Preparation\n",
    "\n",
    "> The SVM Light approach to persisting sparse matrix arrays was used loaded into a Pandas dataframe\n",
    "\n",
    "> The X and Y axis in the SVM Light approach was combined into a two-dimensional Pandas dataframe\n",
    "\n",
    "> Columns that have little merit to the intial analysis were deleted\n",
    "\n",
    "> Pandas columns with empty values (i.e., all zeroes) were deleted\n",
    "\n",
    "> Different type of row and / or columns were separated into different dataframes to analyize the data differently\n",
    "\n",
    "#### Data Visualization\n",
    "\n",
    "> The Hexagon Bin Plot was used to visualize the complete dataset, and it appears a linear coorelation exists among attributes\n",
    "\n",
    "> Individual scatter plots were created for each attribute (non-bin related)\n",
    "\n",
    "## About this Notebook\n",
    "\n",
    "This Jupyter (v4.3.0) notebook was developed on Windows 10 Pro (64 bit) using Anaconda v4.4.7 and Python v3.*.\n",
    "\n",
    "Packages associated with Anaconda were extracted as follows:\n",
    "\n",
    "> conda install -c anaconda pandas\n",
    "\n",
    "> conda install -c anaconda numpy \n",
    "\n",
    "In addition to the packages in Anaconda (and outside of the Anaconda ecosystem), this notebook uses Plotly (v2.2.3) for visualization. The zip file for Plotly can be found on GitHub at (https://github.com/plotly/plotly.py). You can install the Plotly packages as follows:\n",
    "\n",
    "> pip install plotly\n",
    "\n",
    "The version of Pandas and its dependencies are shown below.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* <a href=\"#Section 1: Data Understanding\">Section 1: Data Understanding</a>  \n",
    "> <a href=\"#Section 1.1: About this Dataset (Summary)\">Section 1.1: About this Dataset (Summary)</a>  \n",
    "> <a href=\"#Section 1.2: Description of the Attributes\">Section 1.2: Description of the Attributes</a>  \n",
    "> <a href=\"#Section 1.3: Potentially Useful Attribues\">Section 1.3: Potentially Useful Attribues</a>  \n",
    "> <a href=\"#Section 1.4: Columns and Data Types\">Section 1.4: Columns and Data Types</a>  \n",
    "\n",
    "* <a href=\"#Section 2: Data Preparation\">Section 2: Data Preparation</a>  \n",
    "> <a href=\"#Section 2.1: Download Files\">Section 2.1: Download Files</a>  \n",
    "> <a href=\"#Section 2.2: Pivot the Y-axis\">Section 2.2: Pivot the Y-axis</a>  \n",
    "> <a href=\"#Section 2.3: Convert Sparse Matrix Array to an Array\">Section 2.3: Convert Sparse Matrix Array to an Array</a>  \n",
    "> <a href=\"#Section 2.4: Concatenate the Y-axis before the X-axis\">Section 2.4: Concatenate the Y-axis before the X-axis</a>  \n",
    "> <a href=\"#Section 2.5: Convert the Arrays into Pandas Dataframes\">Section 2.5: Convert the Arrays into Pandas Dataframes</a>  \n",
    "> <a href=\"#Section 2.6: Rename Columns from Integers to Labels\">Section 2.6: Rename Columns from Integers to Labels</a>    \n",
    "> <a href=\"#Section 2.7: Inspecting Missing Values\">Section 2.7: Inspecting Missing Values</a>  \n",
    "> <a href=\"#Section 2.8: Concatenate the Five Pandas Dataframes\">Section 2.8: Concatenate the Five Pandas Dataframes</a>  \n",
    "\n",
    "* <a href=\"#Section 3: Visualizing the Data\">Section 3: Visualizing the Data</a>  \n",
    "> <a href=\"#Section 3.1: Attributes: Box Plots\">Section 3.1: Attributes: Box Plots</a>  \n",
    "> <a href=\"#Section 3.2: Attributes: Hexbin Plots\">Section 3.2: Attributes: Hexbin Plots</a>  \n",
    "> <a href=\"#Section 3.3: Principal Component Analysis (PCA)\">Section 3.3: Principal Component Analysis (PCA)</a>  \n",
    "\n",
    "* <a href=\"#Section 4: Modeling\">Section 4: Modeling</a>  \n",
    "> <a href=\"#Section 4.1: Logistic Regression\">Section 4.1: Logistic Regression</a>  \n",
    "> <a href=\"#Section 4.2: Support Vector Machines\">Section 4.2: Support Vector Machines</a>  \n",
    "\n",
    "* <a href=\"#Section 4: Modeling (New)\"><span style=\"color:red\">Section 4: Modeling (New)</span></a>\n",
    "> <a href=\"#Section 4.1: Linear Regression\"><span style=\"color:red\">Section 4.1: Linear Regression</span></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.6.3.final.0\n",
      "python-bits: 64\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 42 Stepping 7, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: None\n",
      "LOCALE: None.None\n",
      "\n",
      "pandas: 0.20.3\n",
      "pytest: 3.2.1\n",
      "pip: 9.0.1\n",
      "setuptools: 36.5.0.post20170921\n",
      "Cython: 0.26.1\n",
      "numpy: 1.13.3\n",
      "scipy: 1.0.0\n",
      "xarray: None\n",
      "IPython: 6.1.0\n",
      "sphinx: 1.6.3\n",
      "patsy: 0.4.1\n",
      "dateutil: 2.6.1\n",
      "pytz: 2017.2\n",
      "blosc: None\n",
      "bottleneck: 1.2.1\n",
      "tables: 3.4.2\n",
      "numexpr: 2.6.2\n",
      "feather: None\n",
      "matplotlib: 2.1.1\n",
      "openpyxl: 2.4.8\n",
      "xlrd: 1.1.0\n",
      "xlwt: 1.3.0\n",
      "xlsxwriter: 1.0.2\n",
      "lxml: 4.1.0\n",
      "bs4: 4.6.0\n",
      "html5lib: 0.999999999\n",
      "sqlalchemy: 1.1.13\n",
      "pymysql: None\n",
      "psycopg2: None\n",
      "jinja2: 2.9.6\n",
      "s3fs: None\n",
      "pandas_gbq: None\n",
      "pandas_datareader: None\n",
      "Wall time: 7.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Runtime Expectation: The following cell runs about 30 seconds on the first execution of this notebook, and a second or two after that.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.show_versions()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 1: Data Understanding\"></a>\n",
    "\n",
    "# Section 1: Data Understanding\n",
    "\n",
    "<a id=\"Section 1.1: About this Dataset (Summary)\"></a>\n",
    "\n",
    "## Section 1.1: About this Dataset (Summary)\n",
    "\n",
    "This project is comprised of five datasets (bbc.txt, cnn.txt, cnnibn.txt, ndtv.txt, and timesnow.txt), all found at the UCI Machine Learning webset at https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset. Combined, these five datasets have 129,685 instances (rows) and 14 attributes. As shown in the example record below, most of these attributes have multiple data points (often hundreds) and almost all of these values are floating point.\n",
    "\n",
    "> 1  1:123 2:1.316440 3:1.516003 4:5.605905 5:5.346760 6:0.013233 7:0.010729 8:0.091743 9:0.050768 10:3808.067871 11:702.992493 12:7533.133301 13:1390.499268 14:971.098511 15:1894.978027 16:114.965019 17:45.018257 18:0.635224 19:0.095226 20:0.063398 21:0.061210 22:0.038319 23:0.018285 24:0.011113 25:0.007736 26:0.004864 27:0.004220 28:0.003273 29:0.002699 30:0.002553 31:0.002323 32:0.002108 33:0.002036 34:0.001792 35:0.001553 36:0.001250 37:0.001317 38:0.001084 39:0.000818 40:0.000624 41:0.000586 42:0.000529 43:0.000426 44:0.000359 45:0.000446 46:0.000268 47:0.000221 48:0.000154 49:0.000217 50:0.000193 51:0.000163 52:0.000165 53:0.000210 54:0.000114 55:0.000130 56:0.000055 57:0.000013 58:0.733037 59:0.133122 60:0.041263 61:0.019699 62:0.010962 63:0.006927 64:0.004525 65:0.003128 66:0.002314 67:0.001762 68:0.001361 69:0.001065 70:0.000914 71:0.000777 72:0.000667 73:0.000565 74:0.000520 75:0.000467 76:0.000469 77:0.000486 78:0.000417 79:0.000427 80:0.000349 81:0.000258 82:0.000262 83:0.000344 84:0.000168 85:0.000163 86:0.001058 90:0.020584 91:0.185038 92:0.148316 93:0.047098 94:0.169797 95:0.061318 96:0.002200 97:0.010440 98:0.004463 100:0.010558 101:0.002067 102:0.338970 103:0.470364 104:0.189997 105:0.018296 106:0.126517 107:0.047620 108:0.045863 109:0.184865 110:0.095976 111:0.015295 112:0.056323 113:0.024587 115:0.037647 116:0.006015 117:0.160327 118:0.251688 119:0.176144 123:0.006356 219:0.002119 276:0.002119 296:0.341102 448:0.099576 491:0.069915 572:0.141949 573:0.103814 601:0.002119 623:0.050847 726:0.038136 762:0.036017 816:0.036017 871:0.016949 924:0.008475 959:0.036017 1002:0.006356 1016:0.008475 1048:0.002119 4124:0.422333825949 4125:0.663917631952\n",
    "\n",
    "All five datasets are formated in the svmlight / libsvm format. This format is a text-based format, with one sample per line. It is a light format meaning it does not store zero valued features, every fetature that is \"missing\" has a value of zero. The first element of each line is used to store a target variable, and in this case it is the vaue of the atriburtes below. \n",
    "\n",
    "Hence, the file simply contains more records like the one shown above. While there are only 14 attributes in each dataset, most attributes can have more than one column of data. \n",
    "\n",
    "<a id=\"Section 1.2: Description of the Attributes\"></a>\n",
    "\n",
    "## Section 1.2: Description of the Attributes\n",
    "\n",
    "The following sections describe this dataset using the Readme.txt file, examination of the data, and definition of the terms.\n",
    "\n",
    "### Dimension Index (Dependent Variable)\n",
    "\n",
    "This is the dependent variable of Commercial (+1) or Non-Commercial (-1) (i.e., the classification).\n",
    "\n",
    "### Shot Length\n",
    "\n",
    "Commercial video shots are usually short in length, fast visual transitions with peculiar placement of overlaid text bands. Video Shot Length is directly used as one of the feature.\n",
    "\n",
    "### Short time energy\n",
    "\n",
    "Short term energy (STE) can be used for voiced, unvoiced and silence classification of speech. The relation for finding the short term energy can be derived from the total energy relation defined in signal processing. STE is defined as sum of squares of samples in an audio frame. To attract user’s attention commercials generally have higher audio amplitude leading to higher STE.\n",
    "\n",
    "### ZCR\n",
    "Zero Crossing Rate (ZCR) is the rate of sign-changes along a signal. This is used in both speech recognition and music information retrieval and it is a feature used to classify sounds. That is precisely its use here in this dataset, it will be used as one of the attributes to help differentiate commercials from the news program. The Zero Crossing Rate measures how rapidly an audio signal changes. ZCR varies significantly for non-pure speech (High ZCR), music (Moderate ZCR) and speech (Low ZCR). Usually commercials have background music along with speech and hence the use of ZCR as a feature. Audio signals associated with commercials generally have high music content and faster rate of signal change compared to that of non-commercials.\n",
    "\n",
    "### Spectral Centroid\n",
    "\n",
    "Spectral Centroid is a measure of the “center of gravity” using the Fourier transform's frequency and magnitude information. It is commonly used in digital signal processing to help characterize a spectrum. This motivated the use of spectral features where higher Spectral Centroid signify higher frequencies (music).\n",
    "\n",
    "### Spectral Roll off\n",
    "\n",
    "Spectral Roll off Point is a measure of the amount of the right-skewedness of the power spectrum. This feature discriminates between speech, music and non-pure speech.\n",
    "\n",
    "### Spectral Flux\n",
    "\n",
    "Spectral flux is a measure of how quickly the power spectrum of a signal changes. It is calculated by comparing the power spectrum for one frame against the power spectrum from the previous frame.\n",
    "\n",
    "### Fundamental Frequency\n",
    "\n",
    "The fundamental frequency is the lowest frequency of a waveform. In music, the fundamental is the musical pitch of a note that is perceived as the lowest fundamental frequency present. This feature is also used as non-commercials (dominated by pure speech) will produce lower fundamental frequencies compared to that of commercials (dominated by music).\n",
    "\n",
    "### Motion Distribution\n",
    "\n",
    "Motion Distribution is obtained by first computing dense optical flow (Horn-Schunk formulation) followed by construction of a distribution of flow magnitudes over the entire shot with 40 uniformly divided bins in range of [0, 40]. Motion Distribution is a significant feature as many previous works have indicated that commercial shots mostly have high motion content as they try to convey maximum information in minimum possible time.\n",
    "\n",
    "### Frame Difference Distribution\n",
    "\n",
    "The Frame Difference Distribution is the measure of the difference between the current frame and a reference frame, often called \"background image\", or \"background model\". This will assist in measuring the perceived speed at which the frames appear to differentiate. Sudden changes in pixel intensities are grasped by Frame Difference Distribution. Such changes are not registered by optical flow. Thus, Frame Difference Distribution is also computed along with flow magnitude distributions. The researchers obtain the frame difference by averaging absolute frame difference in each of 3 color channels and the distribution is constructed with 32 bins in the range of [0, 255].\n",
    "\n",
    "### Text area distribution\n",
    "\n",
    "The text area distribution is like the text area distribution in that is the measure of the difference between the current text on screen and a reference amount of text. The text distribution feature is obtained by averaging the fraction of text area present in a grid block over all frames of the shot.\n",
    "Bag of Audio Words\n",
    "This attribute is to be removed to reduce the sparseness of the data set.\n",
    "\n",
    "### Bag of Audio Words (4000 bins)\n",
    "\n",
    "The MFCC Bag of Audio Words have been successfully used in several existing speech / audio processing applications. MFCC coefficients along with Delta and Delta-Delta Cepstrum are computed from 150 hours of audio tracks. These coefficients are clustered into 4,000 groups which form the Audio words. Each shot is then represented as a 4,000 Dimensional Bag of Audio Words by forming the normalized histograms of the MFCC's extracted from 20 ms windows with overlap of 10 ms in the shots.\n",
    "\n",
    "###  Edge change Ratio\n",
    "\n",
    "Edge Change Ratio Captures the motion of edges between consecutive frames and is defined as ratio of displaced edge pixels to the total number of edge pixels in a frame. The researchers calculated the mean and variance of the ECR over the entire shot.\n",
    "\n",
    "<a id=\"Section 1.3: Potentially Useful Attribues\"></a>\n",
    "\n",
    "## Section 1.3: Potentially Useful Attribues\n",
    "\n",
    "* A broadcast company code and/or name (there are five broadcast companies in this dataset)\n",
    "* The volume of the audio (commercials tend to be louder in volume than the show)\n",
    "\n",
    "<a id=\"Section 1.4: Columns and Data Types\"></a>\n",
    "\n",
    "## Section 1.4: Columns and Data Types\n",
    "\n",
    "The table below shows the attributes and their data types in tabular format for quick review.\n",
    "\n",
    "NOTE: There are inconsistencies in the column indexing per the readme.txt file - all relating to binning, the Motion Distribution attribute (18-58) should be columns 18-57 leaving column 58 as a 'filler' with an unknown value. Likewise, the Frame Difference Distribution attribute (59-91) should be columns 59-90 leaving column 91 as a 'filler' with an unknown value. The Text Area Distribution attribute (92-122) should be columns 92-121 leaving column 122 as a 'filler with an unknown value. One hint that the indexing is off is the binning attributes ending in an even number rather than an odd number. While the filler values are unknown, they are still included in the dataframes, and, therefore, the models. So while their labels may be a bit unclear, the actual values in those columns are still being used as input into our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are using a Pandas dataframe to tabulate the data (and provide an simple introduction into Pandas)\n",
    "\n",
    "df_attributes = pd.DataFrame(\n",
    "  data=[\n",
    "    ('Dimension Index','0','integer','Categorical','Target variable'),\n",
    "    ('Shot Length','1','integer','Continuous',''),\n",
    "    ('Motion Distribution','2-3','float','Continuous','Mean and Variance'),\n",
    "    ('Frame Difference Distribution','4-5','float','Continuous','Mean and Variance'),\n",
    "    ('Short time energy','6-7','float','Continuous','Mean and Variance'),\n",
    "    ('ZCR','8-9','float','Continuous','Mean and Variance'),\n",
    "    ('Spectral Centroid','10-11','float','Continuous','Mean and Variance'),\n",
    "    ('Spectral Roll off','12-13','float','Continuous','Mean and Variance'),\n",
    "    ('Spectral Flux','14-15','float','Continuous','Mean and Variance'),\n",
    "    ('Fundamental Frequency','16-17','float','Continuous','Mean and Variance'),\n",
    "    ('Motion Distribution','18-57','float','Continuous','40 bins'),\n",
    "    ('Filler','58', 'float','Continuous','Unknown value'),\n",
    "    ('Frame Difference Distribution','59-90','float','Continuous','32 bins'),\n",
    "    ('Filler','91', 'float','Continuous','Unknown value'),\n",
    "    ('Text area distribution','92-121','float','Continuous','15 bins Mean and 15 bins for variance'),\n",
    "    ('Filler','122', 'float','Continuous','Unknown value'),\n",
    "    ('Bag of Audio Words','123-4123','float','Continuous','4,000 bins'), \n",
    "    ('Edge change Ratio','4124-4125','float','Continuous','Mean and Variance')\n",
    "  ],\n",
    "  columns=[\n",
    "    'Attribute Name','Columns','Data Types', 'Type', 'Notes'\n",
    "  ],\n",
    ")\n",
    "\n",
    "# we will later omit the Bag of Audio Words attribute,\"123-4123\" to reduce the sparcity of the data.\n",
    "# tabulate is used to left justify these string value columns (versus the right-justified default)\n",
    "\n",
    "#from tabulate import tabulate\n",
    "\n",
    "#print(tabulate(df_attributes, showindex=True, headers=df_attributes.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2: Data Preparation\"></a>\n",
    "\n",
    "# Section 2: Data Preparation\n",
    "\n",
    "This section covers the activities needed to construct the dataset that will be fed into the models. The files for this project  (bbc.txt, cnn.txt, cnnibn.txt, ndtv.txt, and timesnow.txt) can be found at  https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset as a single ZIP file. To eliminate  manual work and streamline file processing, these five files were extracted and put on a team member's website (http://www.shookfamily.org) as follows:\n",
    "\n",
    "http://www.shookfamily.org/data/BBC.txt (17,720 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/CNN.txt (22,545 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/CNNIBN.txt (33,117 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/NDTV.txt (17,051 lines)\n",
    "\n",
    "http://www.shookfamily.org/data/TIMESNOW.txt (39,252 lines)\n",
    "\n",
    "As shown in the cells below, it takes several steps to download the files and process them into the final dataset.\n",
    "\n",
    "The overall goal is to download the files from the internet and load them into an in-memory object. Because these files are stored in the SVM Light format, they are first loaded into a scipy.sparse matrix array object. These sparse matrix arrays are then inspected to eliminate as many columns as possible, and, consequently, reduce the sparseness of the matrix. Once that is accomplished, the scipy.sparse matrix arrays are converted to Pandas DataFrames for faster data processing and input into the accompanying data models.\n",
    "\n",
    "<a id=\"Section 2.1: Download Files\"></a>\n",
    "\n",
    "## Section 2.1: Download Files\n",
    "\n",
    "The first step in this proces is to download the five files from the internet. The data is in a pickled (marshalled / serialized) format used to persist an SVM Light dataset. The SVM Light format is basically an Index : Value pair where the index represents an element in a sparse matrix array and the value associated with that element. For example, a partial record like the following:\n",
    "\n",
    "> 1 1:123 2:1.316440 3:1.516003 ...\n",
    "\n",
    "represents the Y-axis lable followed by the X-Axis values where the first, second, and third elements are a sparse matrix array with the values 123, 1.316440, and 1.516003 (or array[0] == 123, array[1] == 1.316440, and array[2] == 1.516003. The code below downloads each SVM Light file from the internet as a scipy.sparse matrix object and converts this to as two numpy arrays X and Y representing the X axis and the Y axis.\n",
    "\n",
    "<b>Runtime Expectation:</b> It takes about 30 to 60 seconds to download and convert these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading datasets from the internet ...\n",
      "\n",
      "Downloading (as scipy.sparse matrix) ... http://www.shookfamily.org/data/BBC.txt\n",
      "Wall time: 13.6 s\n",
      "Wall time: 7 s\n",
      "Wall time: 9.91 s\n",
      "Wall time: 5.22 s\n",
      "Wall time: 10.7 s\n",
      "\n",
      "All files have been downloaded\n",
      "Wall time: 47.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import urllib.request\n",
    "import tempfile\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "url_bbc      = 'http://www.shookfamily.org/data/BBC.txt'\n",
    "url_cnn      = 'http://www.shookfamily.org/data/CNN.txt'\n",
    "url_cnnibn   = 'http://www.shookfamily.org/data/CNNIBN.txt'\n",
    "url_ndtv     = 'http://www.shookfamily.org/data/NDTV.txt'\n",
    "url_timesnow = 'http://www.shookfamily.org/data/TIMESNOW.txt'\n",
    "\n",
    "################################################################################\n",
    "# Download file to a temporary file. Load that file into a scipy.sparse matrix\n",
    "# array, and then return that object to the caller.\n",
    "################################################################################\n",
    "\n",
    "def get_pickled_file(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    text = data.decode('utf-8') # a `str`; this step can't be used if data is binary\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w') as file_handle:\n",
    "        assert text is not None\n",
    "        file_handle.write(text)\n",
    "        filename = file_handle.name\n",
    "\n",
    "        return load_svmlight_file(filename)   # Returns the X axis and  Y axis\n",
    "\n",
    "################################################################################\n",
    "# Dowload files as scipy.sparse matrix arrays\n",
    "################################################################################\n",
    "\n",
    "print('Downloading datasets from the internet ...\\n')\n",
    "print('Downloading (as scipy.sparse matrix) ...', url_bbc)\n",
    "\n",
    "%time X1, y1 = get_pickled_file(url_bbc)\n",
    "%time X2, y2 = get_pickled_file(url_cnn)\n",
    "%time X3, y3 = get_pickled_file(url_cnnibn)\n",
    "%time X4, y4 = get_pickled_file(url_ndtv)\n",
    "%time X5, y5 = get_pickled_file(url_timesnow)\n",
    "\n",
    "print('\\nAll files have been downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.2: Pivot the Y-axis\"></a>\n",
    "\n",
    "## Section 2.2: Pivot the Y-axis\n",
    "\n",
    "The Y-axis variables (y1, y2, y3, y4, y5) are returned from the cell above as arrays in a column-wise orientation:\n",
    "\n",
    "> array([ 1.,  1.,  1., ...,  1.,  1.,  1.])\n",
    "\n",
    "The code below pivots those arrays to a row-wise orientation:\n",
    "\n",
    "> array(  \n",
    "&nbsp;&nbsp;[  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.],  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[ 1.]  \n",
    "&nbsp;&nbsp;]  \n",
    ")\n",
    "\n",
    "<b>Runtime Expectation:</b> It takes less than a second to run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Y1 = y1[:, None]   # bbc\n",
    "Y2 = y2[:, None]   # cnn\n",
    "Y3 = y3[:, None]   # cnnibn\n",
    "Y4 = y4[:, None]   # ndtv\n",
    "Y5 = y5[:, None]   # timesnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.3: Convert Sparse Matrix Array to an Array\"></a>\n",
    "\n",
    "## Section 2.3: Convert Sparse Matrix Array to an Array\n",
    "\n",
    "The first five cells display some information about each sparse matrix array. The last cell converts those sparse matrix array into a dense array.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<17720x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1813150 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X1  # bbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<22545x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2895841 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X2  # cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<33117x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4189576 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X3  # cnnibn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<17051x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2150834 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X4  # ndtv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<39252x4125 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4992517 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X5  # timesnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 528 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_dense1 = X1.toarray()  # bbc\n",
    "X_dense2 = X2.toarray()  # cnn\n",
    "X_dense3 = X3.toarray()  # cnnibn\n",
    "X_dense4 = X4.toarray()  # ndtv\n",
    "X_dense5 = X5.toarray()  # timesnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.4: Concatenate the Y-axis before the X-axis\"></a>\n",
    "\n",
    "## Section 2.4: Concatenate the Y-axis before the X-axis\n",
    "\n",
    "Now that the Y-axis has been pivoted from a column-wise orientation to a row-wise orientation, we can concatenate the two arrays so the Y-axis is i\n",
    "nserted before the X-axis. This places the Dependent Variable in the first column followed by the Independent Variables.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 10 to 15 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "concat1 = np.hstack((Y1, X_dense1))  # bbc\n",
    "concat2 = np.hstack((Y2, X_dense2))  # cnn\n",
    "concat3 = np.hstack((Y3, X_dense3))  # cnnibn\n",
    "concat4 = np.hstack((Y4, X_dense4))  # ndtv\n",
    "concat5 = np.hstack((Y5, X_dense5))  # timesnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.5: Convert the Arrays into Pandas Dataframes\"></a>\n",
    "\n",
    "## Section 2.5: Convert the Arrays into Pandas Dataframes\n",
    "\n",
    "The following code converts the concatenated dense arrays into Pandas dataframes (to get them into the Pandas ecosystem).\n",
    "\n",
    "### Section 2.5.1: Convert the First Set of Dataframes (no BoWs)\n",
    "\n",
    "The first set of dataframes will be used to model without the Bag of Words.\n",
    "\n",
    "This set of dataframes is consistent with the data preparation, visualization, and modeling in Lab 1 and the MiniLab (where we had deleted the Bag of Words to simplify those projects).\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a second or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17720 22545 33117 17051 39252 129685\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 16.9 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 21.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 31.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 16.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 125 entries, 0 to 4125\n",
      "dtypes: float64(125)\n",
      "memory usage: 37.4 MB\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_bbc      = pd.DataFrame(concat1)\n",
    "df_cnn      = pd.DataFrame(concat2)\n",
    "df_cnnibn   = pd.DataFrame(concat3)\n",
    "df_ndtv     = pd.DataFrame(concat4)\n",
    "df_timesnow = pd.DataFrame(concat5)\n",
    "\n",
    "print(len(df_bbc.index), len(df_cnn.index), len(df_cnnibn.index), len(df_ndtv.index), len(df_timesnow.index),\n",
    "    len(df_bbc.index) + len(df_cnn.index) + len(df_cnnibn.index) + len(df_ndtv.index) + len(df_timesnow.index))\n",
    "\n",
    "drop_cols = np.arange(123, 4124)\n",
    "\n",
    "df_bbc      = df_bbc.drop(drop_cols, 1)\n",
    "df_cnn      = df_cnn.drop(drop_cols, 1)\n",
    "df_cnnibn   = df_cnnibn.drop(drop_cols, 1)\n",
    "df_ndtv     = df_ndtv.drop(drop_cols, 1)\n",
    "df_timesnow = df_timesnow.drop(drop_cols, 1)\n",
    "\n",
    "df_bbc.info()\n",
    "df_cnn.info()\n",
    "df_cnnibn.info()\n",
    "df_ndtv.info()\n",
    "df_timesnow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5.2: Convert the Second Set of Dataframes (BoWs)\n",
    "\n",
    "The second set of dataframes will be used to model with the Bag of Words (*_bow).\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 10 to 20 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17720 22545 33117 17051 39252 129685\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17720 entries, 0 to 17719\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 541.0 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22545 entries, 0 to 22544\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 688.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 1011.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17051 entries, 0 to 17050\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 520.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39252 entries, 0 to 39251\n",
      "Columns: 4002 entries, 0 to 4123\n",
      "dtypes: float64(4002)\n",
      "memory usage: 1.2 GB\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_bbc_bow      = pd.DataFrame(concat1)   # df_bbc_bow (*_bag_of_words)\n",
    "df_cnn_bow      = pd.DataFrame(concat2)\n",
    "df_cnnibn_bow   = pd.DataFrame(concat3)\n",
    "df_ndtv_bow     = pd.DataFrame(concat4)\n",
    "df_timesnow_bow = pd.DataFrame(concat5)\n",
    "\n",
    "print(len(df_bbc_bow.index), len(df_cnn_bow.index), len(df_cnnibn_bow.index), len(df_ndtv_bow.index),\n",
    "    len(df_timesnow_bow.index), len(df_bbc_bow.index) + len(df_cnn_bow.index) + len(df_cnnibn_bow.index) +\n",
    "    len(df_ndtv_bow.index) + len(df_timesnow_bow.index))\n",
    "\n",
    "drop_cols = np.append(np.arange(1, 123), np.arange(4124, 4126))\n",
    "\n",
    "df_bbc_bow      = df_bbc_bow.drop(drop_cols, 1)\n",
    "df_cnn_bow      = df_cnn_bow.drop(drop_cols, 1)\n",
    "df_cnnibn_bow   = df_cnnibn_bow.drop(drop_cols, 1)\n",
    "df_ndtv_bow     = df_ndtv_bow.drop(drop_cols, 1)\n",
    "df_timesnow_bow = df_timesnow_bow.drop(drop_cols, 1)\n",
    "\n",
    "df_bbc_bow.info()\n",
    "df_cnn_bow.info()\n",
    "df_cnnibn_bow.info()\n",
    "df_ndtv_bow.info()\n",
    "df_timesnow_bow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.6: Rename Columns from Integers to Labels\"></a>\n",
    "\n",
    "## Section 2.6: Rename Columns from Integers to Labels\n",
    "\n",
    "### Section 2.6.1: Rename the First Set of Dataframes (no BoWs)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in less than a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dimension Index  Shot Length  Motion Distribution-Mean  \\\n",
      "0              1.0        123.0                   1.31644   \n",
      "\n",
      "   Motion Distribution-Variance  Frame Difference Distribution-Mean  \\\n",
      "0                      1.516003                            5.605905   \n",
      "\n",
      "   Frame Difference Distribution-Variance  Short time energy-Mean  \\\n",
      "0                                 5.34676                0.013233   \n",
      "\n",
      "   Short time energy-Variance  ZCR-Mean  ZCR-Variance  \\\n",
      "0                    0.010729  0.091743      0.050768   \n",
      "\n",
      "              ...              Text area distribution-Bin 9-Variance  \\\n",
      "0             ...                                           0.037647   \n",
      "\n",
      "   Text area distribution-Bin 10-Variance  \\\n",
      "0                                0.006015   \n",
      "\n",
      "   Text area distribution-Bin 11-Variance  \\\n",
      "0                                0.160327   \n",
      "\n",
      "   Text area distribution-Bin 12-Variance  \\\n",
      "0                                0.251688   \n",
      "\n",
      "   Text area distribution-Bin 13-Variance  \\\n",
      "0                                0.176144   \n",
      "\n",
      "   Text area distribution-Bin 14-Variance  \\\n",
      "0                                     0.0   \n",
      "\n",
      "   Text area distribution-Bin 15-Variance  \\\n",
      "0                                     0.0   \n",
      "\n",
      "   Attribute 122 should be Bin 15-Variance  Edge change Ratio-Mean  \\\n",
      "0                                      0.0                0.422334   \n",
      "\n",
      "   Edge change Ratio-Variance  \n",
      "0                    0.663918  \n",
      "\n",
      "[1 rows x 125 columns]\n",
      "Wall time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ren_cols = np.array([\n",
    "    'Dimension Index',\n",
    "    'Shot Length',\n",
    "    'Motion Distribution-Mean', 'Motion Distribution-Variance',\n",
    "    'Frame Difference Distribution-Mean', 'Frame Difference Distribution-Variance',\n",
    "    'Short time energy-Mean', 'Short time energy-Variance',\n",
    "    'ZCR-Mean', 'ZCR-Variance',\n",
    "    'Spectral Centroid-Mean', 'Spectral Centroid-Variance',\n",
    "    'Spectral Roll off-Mean', 'Spectral Roll off-Variance',\n",
    "    'Spectral Flux-Mean', 'Spectral Flux-Variance',\n",
    "    'Fundamental Frequency-Mean', 'Fundamental Frequency-Variance',\n",
    "    'Motion Distribution-Bin 1', 'Motion Distribution-Bin 2', 'Motion Distribution-Bin 3', 'Motion Distribution-Bin 4',\n",
    "    'Motion Distribution-Bin 5', 'Motion Distribution-Bin 6', 'Motion Distribution-Bin 7', 'Motion Distribution-Bin 8',\n",
    "    'Motion Distribution-Bin 9', 'Motion Distribution-Bin 10', 'Motion Distribution-Bin 11', 'Motion Distribution-Bin 12',\n",
    "    'Motion Distribution-Bin 13', 'Motion Distribution-Bin 14', 'Motion Distribution-Bin 15', 'Motion Distribution-Bin 16',\n",
    "    'Motion Distribution-Bin 17', 'Motion Distribution-Bin 18', 'Motion Distribution-Bin 19', 'Motion Distribution-Bin 20',\n",
    "    'Motion Distribution-Bin 21', 'Motion Distribution-Bin 22', 'Motion Distribution-Bin 23', 'Motion Distribution-Bin 24',\n",
    "    'Motion Distribution-Bin 25', 'Motion Distribution-Bin 26', 'Motion Distribution-Bin 27', 'Motion Distribution-Bin 28',\n",
    "    'Motion Distribution-Bin 29', 'Motion Distribution-Bin 30', 'Motion Distribution-Bin 31', 'Motion Distribution-Bin 32',\n",
    "    'Motion Distribution-Bin 33', 'Motion Distribution-Bin 34', 'Motion Distribution-Bin 35', 'Motion Distribution-Bin 36',\n",
    "    'Motion Distribution-Bin 37', 'Motion Distribution-Bin 38', 'Motion Distribution-Bin 39', 'Motion Distribution-Bin 40',\n",
    "    'Filler 1',\n",
    "    'Frame Difference Distribution-Bin 1', 'Frame Difference Distribution-Bin 2',\n",
    "    'Frame Difference Distribution-Bin 3', 'Frame Difference Distribution-Bin 4',\n",
    "    'Frame Difference Distribution-Bin 5', 'Frame Difference Distribution-Bin 6',\n",
    "    'Frame Difference Distribution-Bin 7', 'Frame Difference Distribution-Bin 8',\n",
    "    'Frame Difference Distribution-Bin 9', 'Frame Difference Distribution-Bin 10',\n",
    "    'Frame Difference Distribution-Bin 11', 'Frame Difference Distribution-Bin 12',\n",
    "    'Frame Difference Distribution-Bin 13', 'Frame Difference Distribution-Bin 14',\n",
    "    'Frame Difference Distribution-Bin 15', 'Frame Difference Distribution-Bin 16',\n",
    "    'Frame Difference Distribution-Bin 17', 'Frame Difference Distribution-Bin 18',\n",
    "    'Frame Difference Distribution-Bin 19', 'Frame Difference Distribution-Bin 20',\n",
    "    'Frame Difference Distribution-Bin 21', 'Frame Difference Distribution-Bin 22',\n",
    "    'Frame Difference Distribution-Bin 23', 'Frame Difference Distribution-Bin 24',\n",
    "    'Frame Difference Distribution-Bin 25', 'Frame Difference Distribution-Bin 26',\n",
    "    'Frame Difference Distribution-Bin 27', 'Frame Difference Distribution-Bin 28',\n",
    "    'Frame Difference Distribution-Bin 29', 'Frame Difference Distribution-Bin 30',\n",
    "    'Frame Difference Distribution-Bin 31', 'Frame Difference Distribution-Bin 32',\n",
    "    'Filler 2',\n",
    "    'Text area distribution-Bin 1-Mean', 'Text area distribution-Bin 2-Mean',\n",
    "    'Text area distribution-Bin 3-Mean', 'Text area distribution-Bin 4-Mean',\n",
    "    'Text area distribution-Bin 5-Mean', 'Text area distribution-Bin 6-Mean',\n",
    "    'Text area distribution-Bin 7-Mean', 'Text area distribution-Bin 8-Mean',\n",
    "    'Text area distribution-Bin 9-Mean', 'Text area distribution-Bin 10-Mean',\n",
    "    'Text area distribution-Bin 11-Mean', 'Text area distribution-Bin 12-Mean',\n",
    "    'Text area distribution-Bin 13-Mean', 'Text area distribution-Bin 14-Mean',\n",
    "    'Text area distribution-Bin 15-Mean',\n",
    "    'Text area distribution-Bin 1-Variance', 'Text area distribution-Bin 2-Variance',\n",
    "    'Text area distribution-Bin 3-Variance', 'Text area distribution-Bin 4-Variance',\n",
    "    'Text area distribution-Bin 5-Variance', 'Text area distribution-Bin 6-Variance',\n",
    "    'Text area distribution-Bin 7-Variance', 'Text area distribution-Bin 8-Variance',\n",
    "    'Text area distribution-Bin 9-Variance', 'Text area distribution-Bin 10-Variance',\n",
    "    'Text area distribution-Bin 11-Variance', 'Text area distribution-Bin 12-Variance',\n",
    "    'Text area distribution-Bin 13-Variance', 'Text area distribution-Bin 14-Variance',\n",
    "    'Text area distribution-Bin 15-Variance', 'Attribute 122 should be Bin 15-Variance',\n",
    "    'Edge change Ratio-Mean', 'Edge change Ratio-Variance'\n",
    "])\n",
    "    \n",
    "df_bbc.columns = ren_cols\n",
    "df_cnn.columns = ren_cols\n",
    "df_cnnibn.columns = ren_cols\n",
    "df_ndtv.columns = ren_cols\n",
    "df_timesnow.columns = ren_cols\n",
    "\n",
    "print(df_bbc.iloc[0:1:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.6.2: Rename the Second Set of Dataframes (BoWs)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in less than a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4002\n",
      "['Dimension Index' 'BoW 1' 'BoW 2' ..., 'BoW 3999' 'BoW 4000' 'BoW 4001']\n",
      "   Dimension Index     BoW 1  BoW 2  BoW 3  BoW 4  BoW 5  BoW 6  BoW 7  BoW 8  \\\n",
      "0              1.0  0.006356    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   BoW 9    ...     BoW 3992  BoW 3993  BoW 3994  BoW 3995  BoW 3996  \\\n",
      "0    0.0    ...          0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   BoW 3997  BoW 3998  BoW 3999  BoW 4000  BoW 4001  \n",
      "0       0.0       0.0       0.0       0.0       0.0  \n",
      "\n",
      "[1 rows x 4002 columns]\n",
      "Wall time: 165 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ren_cols = np.array(['Dimension Index'])\n",
    "\n",
    "print(ren_cols.size)\n",
    "\n",
    "for i in np.arange(1, 4002):\n",
    "    ren_cols = np.append(ren_cols, 'BoW ' + str(i))\n",
    "\n",
    "print(ren_cols.size)\n",
    "print(ren_cols)\n",
    "\n",
    "df_bbc_bow.columns = ren_cols\n",
    "df_cnn_bow.columns = ren_cols\n",
    "df_cnnibn_bow.columns = ren_cols\n",
    "df_ndtv_bow.columns = ren_cols\n",
    "df_timesnow_bow.columns = ren_cols\n",
    "\n",
    "print(df_bbc_bow.iloc[0:1:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.7: Inspecting Missing Values\"></a>\n",
    "\n",
    "## Section 2.7: Inspecting Missing Values\n",
    "\n",
    "As shown is the output above, 120 columns are left in the dataframe. 4,005 columns were deleted after eliminating the Bag of Words (4,000 columns) and the five columns (88, 89, 120, 121, 123) with all zero values.\n",
    "\n",
    "###  Section 2.7.1: Display Table of Missing Values\n",
    "\n",
    "The code below displays columns with SOME missing values (versus ALL missing values).\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dimension Index</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shot Length</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Mean</th>\n",
       "      <td>4014</td>\n",
       "      <td>22.652370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Variance</th>\n",
       "      <td>4014</td>\n",
       "      <td>22.652370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short time energy-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short time energy-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZCR-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZCR-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Centroid-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Centroid-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Roll off-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Roll off-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Flux-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral Flux-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fundamental Frequency-Mean</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fundamental Frequency-Variance</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 1</th>\n",
       "      <td>4013</td>\n",
       "      <td>22.646727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 2</th>\n",
       "      <td>4014</td>\n",
       "      <td>22.652370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 3</th>\n",
       "      <td>4015</td>\n",
       "      <td>22.658014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 4</th>\n",
       "      <td>4015</td>\n",
       "      <td>22.658014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 5</th>\n",
       "      <td>4031</td>\n",
       "      <td>22.748307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 6</th>\n",
       "      <td>4057</td>\n",
       "      <td>22.895034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 7</th>\n",
       "      <td>4083</td>\n",
       "      <td>23.041761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 8</th>\n",
       "      <td>4116</td>\n",
       "      <td>23.227991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 9</th>\n",
       "      <td>4169</td>\n",
       "      <td>23.527088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 10</th>\n",
       "      <td>4226</td>\n",
       "      <td>23.848758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 11</th>\n",
       "      <td>4263</td>\n",
       "      <td>24.057562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 12</th>\n",
       "      <td>4311</td>\n",
       "      <td>24.328442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 4-Mean</th>\n",
       "      <td>9514</td>\n",
       "      <td>53.690745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 5-Mean</th>\n",
       "      <td>9002</td>\n",
       "      <td>50.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 6-Mean</th>\n",
       "      <td>8201</td>\n",
       "      <td>46.281038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 7-Mean</th>\n",
       "      <td>8773</td>\n",
       "      <td>49.509029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 8-Mean</th>\n",
       "      <td>7572</td>\n",
       "      <td>42.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 9-Mean</th>\n",
       "      <td>7270</td>\n",
       "      <td>41.027088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 10-Mean</th>\n",
       "      <td>8188</td>\n",
       "      <td>46.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 11-Mean</th>\n",
       "      <td>4712</td>\n",
       "      <td>26.591422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 12-Mean</th>\n",
       "      <td>4808</td>\n",
       "      <td>27.133183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 13-Mean</th>\n",
       "      <td>5838</td>\n",
       "      <td>32.945824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 14-Mean</th>\n",
       "      <td>11427</td>\n",
       "      <td>64.486456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 15-Mean</th>\n",
       "      <td>11109</td>\n",
       "      <td>62.691874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 1-Variance</th>\n",
       "      <td>9232</td>\n",
       "      <td>52.099323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 2-Variance</th>\n",
       "      <td>9807</td>\n",
       "      <td>55.344244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 3-Variance</th>\n",
       "      <td>9196</td>\n",
       "      <td>51.896163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 4-Variance</th>\n",
       "      <td>9514</td>\n",
       "      <td>53.690745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 5-Variance</th>\n",
       "      <td>9002</td>\n",
       "      <td>50.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 6-Variance</th>\n",
       "      <td>8201</td>\n",
       "      <td>46.281038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 7-Variance</th>\n",
       "      <td>8773</td>\n",
       "      <td>49.509029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 8-Variance</th>\n",
       "      <td>7572</td>\n",
       "      <td>42.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 9-Variance</th>\n",
       "      <td>7270</td>\n",
       "      <td>41.027088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 10-Variance</th>\n",
       "      <td>8188</td>\n",
       "      <td>46.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 11-Variance</th>\n",
       "      <td>4712</td>\n",
       "      <td>26.591422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 12-Variance</th>\n",
       "      <td>4808</td>\n",
       "      <td>27.133183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 13-Variance</th>\n",
       "      <td>5838</td>\n",
       "      <td>32.945824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 14-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 15-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute 122 should be Bin 15-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edge change Ratio-Mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edge change Ratio-Variance</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Missing Values  % of Total Values\n",
       "Dimension Index                                       0           0.000000\n",
       "Shot Length                                           0           0.000000\n",
       "Motion Distribution-Mean                           4014          22.652370\n",
       "Motion Distribution-Variance                       4014          22.652370\n",
       "Frame Difference Distribution-Mean                 4013          22.646727\n",
       "Frame Difference Distribution-Variance             4013          22.646727\n",
       "Short time energy-Mean                             4013          22.646727\n",
       "Short time energy-Variance                         4013          22.646727\n",
       "ZCR-Mean                                           4013          22.646727\n",
       "ZCR-Variance                                       4013          22.646727\n",
       "Spectral Centroid-Mean                             4013          22.646727\n",
       "Spectral Centroid-Variance                         4013          22.646727\n",
       "Spectral Roll off-Mean                             4013          22.646727\n",
       "Spectral Roll off-Variance                         4013          22.646727\n",
       "Spectral Flux-Mean                                 4013          22.646727\n",
       "Spectral Flux-Variance                             4013          22.646727\n",
       "Fundamental Frequency-Mean                         4013          22.646727\n",
       "Fundamental Frequency-Variance                     4013          22.646727\n",
       "Motion Distribution-Bin 1                          4013          22.646727\n",
       "Motion Distribution-Bin 2                          4014          22.652370\n",
       "Motion Distribution-Bin 3                          4015          22.658014\n",
       "Motion Distribution-Bin 4                          4015          22.658014\n",
       "Motion Distribution-Bin 5                          4031          22.748307\n",
       "Motion Distribution-Bin 6                          4057          22.895034\n",
       "Motion Distribution-Bin 7                          4083          23.041761\n",
       "Motion Distribution-Bin 8                          4116          23.227991\n",
       "Motion Distribution-Bin 9                          4169          23.527088\n",
       "Motion Distribution-Bin 10                         4226          23.848758\n",
       "Motion Distribution-Bin 11                         4263          24.057562\n",
       "Motion Distribution-Bin 12                         4311          24.328442\n",
       "...                                                 ...                ...\n",
       "Text area distribution-Bin 4-Mean                  9514          53.690745\n",
       "Text area distribution-Bin 5-Mean                  9002          50.801354\n",
       "Text area distribution-Bin 6-Mean                  8201          46.281038\n",
       "Text area distribution-Bin 7-Mean                  8773          49.509029\n",
       "Text area distribution-Bin 8-Mean                  7572          42.731377\n",
       "Text area distribution-Bin 9-Mean                  7270          41.027088\n",
       "Text area distribution-Bin 10-Mean                 8188          46.207675\n",
       "Text area distribution-Bin 11-Mean                 4712          26.591422\n",
       "Text area distribution-Bin 12-Mean                 4808          27.133183\n",
       "Text area distribution-Bin 13-Mean                 5838          32.945824\n",
       "Text area distribution-Bin 14-Mean                11427          64.486456\n",
       "Text area distribution-Bin 15-Mean                11109          62.691874\n",
       "Text area distribution-Bin 1-Variance              9232          52.099323\n",
       "Text area distribution-Bin 2-Variance              9807          55.344244\n",
       "Text area distribution-Bin 3-Variance              9196          51.896163\n",
       "Text area distribution-Bin 4-Variance              9514          53.690745\n",
       "Text area distribution-Bin 5-Variance              9002          50.801354\n",
       "Text area distribution-Bin 6-Variance              8201          46.281038\n",
       "Text area distribution-Bin 7-Variance              8773          49.509029\n",
       "Text area distribution-Bin 8-Variance              7572          42.731377\n",
       "Text area distribution-Bin 9-Variance              7270          41.027088\n",
       "Text area distribution-Bin 10-Variance             8188          46.207675\n",
       "Text area distribution-Bin 11-Variance             4712          26.591422\n",
       "Text area distribution-Bin 12-Variance             4808          27.133183\n",
       "Text area distribution-Bin 13-Variance             5838          32.945824\n",
       "Text area distribution-Bin 14-Variance            17720         100.000000\n",
       "Text area distribution-Bin 15-Variance            17720         100.000000\n",
       "Attribute 122 should be Bin 15-Variance           17720         100.000000\n",
       "Edge change Ratio-Mean                                0           0.000000\n",
       "Edge change Ratio-Variance                            0           0.000000\n",
       "\n",
       "[125 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percentage_of_zeros_table(df):\n",
    "    numberOf_nonzeros = df.astype(bool).sum(axis=0)\n",
    "    NumberOf_Zeros = df.count()-numberOf_nonzeros\n",
    "    percentOf_Zeros=NumberOf_Zeros / df.count() * 100\n",
    "    table1 = pd.concat([NumberOf_Zeros, percentOf_Zeros], axis=1)\n",
    "    table2 = table1.rename(columns={0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    return table2\n",
    "\n",
    "df_missing_values_table1 = percentage_of_zeros_table(df_bbc)\n",
    "df_missing_values_table2 = percentage_of_zeros_table(df_cnn)\n",
    "df_missing_values_table3 = percentage_of_zeros_table(df_cnnibn)\n",
    "df_missing_values_table4 = percentage_of_zeros_table(df_ndtv)\n",
    "df_missing_values_table5 = percentage_of_zeros_table(df_timesnow)\n",
    "\n",
    "df_missing_values_table1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.7.2: View Missing Values via a Threshold (40%)\n",
    "\n",
    "The code below displays columns having over 40% of its values as zero.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 39</th>\n",
       "      <td>7221</td>\n",
       "      <td>40.750564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Distribution-Bin 40</th>\n",
       "      <td>7330</td>\n",
       "      <td>41.365688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 26</th>\n",
       "      <td>8214</td>\n",
       "      <td>46.354402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 27</th>\n",
       "      <td>10460</td>\n",
       "      <td>59.029345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 28</th>\n",
       "      <td>13404</td>\n",
       "      <td>75.643341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 29</th>\n",
       "      <td>17650</td>\n",
       "      <td>99.604966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 30</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 31</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frame Difference Distribution-Bin 32</th>\n",
       "      <td>11427</td>\n",
       "      <td>64.486456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filler 2</th>\n",
       "      <td>11109</td>\n",
       "      <td>62.691874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 1-Mean</th>\n",
       "      <td>9232</td>\n",
       "      <td>52.099323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 2-Mean</th>\n",
       "      <td>9807</td>\n",
       "      <td>55.344244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 3-Mean</th>\n",
       "      <td>9197</td>\n",
       "      <td>51.901806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 4-Mean</th>\n",
       "      <td>9514</td>\n",
       "      <td>53.690745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 5-Mean</th>\n",
       "      <td>9002</td>\n",
       "      <td>50.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 6-Mean</th>\n",
       "      <td>8201</td>\n",
       "      <td>46.281038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 7-Mean</th>\n",
       "      <td>8773</td>\n",
       "      <td>49.509029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 8-Mean</th>\n",
       "      <td>7572</td>\n",
       "      <td>42.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 9-Mean</th>\n",
       "      <td>7270</td>\n",
       "      <td>41.027088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 10-Mean</th>\n",
       "      <td>8188</td>\n",
       "      <td>46.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 14-Mean</th>\n",
       "      <td>11427</td>\n",
       "      <td>64.486456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 15-Mean</th>\n",
       "      <td>11109</td>\n",
       "      <td>62.691874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 1-Variance</th>\n",
       "      <td>9232</td>\n",
       "      <td>52.099323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 2-Variance</th>\n",
       "      <td>9807</td>\n",
       "      <td>55.344244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 3-Variance</th>\n",
       "      <td>9196</td>\n",
       "      <td>51.896163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 4-Variance</th>\n",
       "      <td>9514</td>\n",
       "      <td>53.690745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 5-Variance</th>\n",
       "      <td>9002</td>\n",
       "      <td>50.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 6-Variance</th>\n",
       "      <td>8201</td>\n",
       "      <td>46.281038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 7-Variance</th>\n",
       "      <td>8773</td>\n",
       "      <td>49.509029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 8-Variance</th>\n",
       "      <td>7572</td>\n",
       "      <td>42.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 9-Variance</th>\n",
       "      <td>7270</td>\n",
       "      <td>41.027088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 10-Variance</th>\n",
       "      <td>8188</td>\n",
       "      <td>46.207675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 14-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text area distribution-Bin 15-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute 122 should be Bin 15-Variance</th>\n",
       "      <td>17720</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Missing Values  % of Total Values\n",
       "Motion Distribution-Bin 39                         7221          40.750564\n",
       "Motion Distribution-Bin 40                         7330          41.365688\n",
       "Frame Difference Distribution-Bin 26               8214          46.354402\n",
       "Frame Difference Distribution-Bin 27              10460          59.029345\n",
       "Frame Difference Distribution-Bin 28              13404          75.643341\n",
       "Frame Difference Distribution-Bin 29              17650          99.604966\n",
       "Frame Difference Distribution-Bin 30              17720         100.000000\n",
       "Frame Difference Distribution-Bin 31              17720         100.000000\n",
       "Frame Difference Distribution-Bin 32              11427          64.486456\n",
       "Filler 2                                          11109          62.691874\n",
       "Text area distribution-Bin 1-Mean                  9232          52.099323\n",
       "Text area distribution-Bin 2-Mean                  9807          55.344244\n",
       "Text area distribution-Bin 3-Mean                  9197          51.901806\n",
       "Text area distribution-Bin 4-Mean                  9514          53.690745\n",
       "Text area distribution-Bin 5-Mean                  9002          50.801354\n",
       "Text area distribution-Bin 6-Mean                  8201          46.281038\n",
       "Text area distribution-Bin 7-Mean                  8773          49.509029\n",
       "Text area distribution-Bin 8-Mean                  7572          42.731377\n",
       "Text area distribution-Bin 9-Mean                  7270          41.027088\n",
       "Text area distribution-Bin 10-Mean                 8188          46.207675\n",
       "Text area distribution-Bin 14-Mean                11427          64.486456\n",
       "Text area distribution-Bin 15-Mean                11109          62.691874\n",
       "Text area distribution-Bin 1-Variance              9232          52.099323\n",
       "Text area distribution-Bin 2-Variance              9807          55.344244\n",
       "Text area distribution-Bin 3-Variance              9196          51.896163\n",
       "Text area distribution-Bin 4-Variance              9514          53.690745\n",
       "Text area distribution-Bin 5-Variance              9002          50.801354\n",
       "Text area distribution-Bin 6-Variance              8201          46.281038\n",
       "Text area distribution-Bin 7-Variance              8773          49.509029\n",
       "Text area distribution-Bin 8-Variance              7572          42.731377\n",
       "Text area distribution-Bin 9-Variance              7270          41.027088\n",
       "Text area distribution-Bin 10-Variance             8188          46.207675\n",
       "Text area distribution-Bin 14-Variance            17720         100.000000\n",
       "Text area distribution-Bin 15-Variance            17720         100.000000\n",
       "Attribute 122 should be Bin 15-Variance           17720         100.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing_values_table1 = df_missing_values_table1[(df_missing_values_table1['% of Total Values'] > 40)]\n",
    "\n",
    "df_missing_values_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.7.3: : Drop Columns with a High Ratio of Missing Values\n",
    "\n",
    "The code below drops column 87, which has about 90% of its values as zero.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Drop column 87 in each of the individual datasets\n",
    "\n",
    "#df_bbc      = df_bbc.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "#df_cnn      = df_cnn.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "#df_cnnibn   = df_cnnibn.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "#df_ndtv     = df_ndtv.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "#df_timesnow = df_timesnow.drop(['Frame Difference Distribution-Bin 29'], axis=1)\n",
    "\n",
    "#df_bbc.info()\n",
    "#df_cnn.info()\n",
    "#df_cnnibn.info()\n",
    "#df_ndtv.info()\n",
    "#df_timesnow.info()\n",
    "\n",
    "# The code below should delete 1 columns (87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 2.8: Concatenate the Five Pandas Dataframes\"></a>\n",
    "\n",
    "## Section 2.8: Concatenate the Five Pandas Dataframes\n",
    "\n",
    "This step concatenates the five Pandas dataframes into the final dataframe.\n",
    "\n",
    "### Section 2.8.1:  Concatenate the First Set of Dataframes (no BoWs)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in less than a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 129685 entries, 0 to 39251\n",
      "Columns: 125 entries, Dimension Index to Edge change Ratio-Variance\n",
      "dtypes: float64(125)\n",
      "memory usage: 124.7 MB\n",
      "Wall time: 78.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_final = pd.concat([df_bbc, df_cnn, df_cnnibn, df_ndtv, df_timesnow])\n",
    "\n",
    "df_final.name = 'TV News Channel Commercial Detection'\n",
    "\n",
    "cols = list(df_final)  # List of the columns as string (to easy indexing)\n",
    "\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.8.2:  Concatenate the Second Set of Dataframes (BoWs)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 10 to 20 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 129685 entries, 0 to 39251\n",
      "Columns: 4002 entries, Dimension Index to BoW 4001\n",
      "dtypes: float64(4002)\n",
      "memory usage: 3.9 GB\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_final_bow = pd.concat([df_bbc_bow, df_cnn_bow, df_cnnibn_bow, df_ndtv_bow, df_timesnow_bow])\n",
    "\n",
    "df_final_bow.name = 'TV News Channel Commercial Detection'\n",
    "\n",
    "cols_bow = list(df_final_bow)  # List of the columns as string (to easy indexing)\n",
    "\n",
    "df_final_bow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 3: Visualizing the Data\"></a>\n",
    "\n",
    "# Section 3: Visualizing the Data \n",
    "\n",
    "<a id=\"Section 3.1: Attributes: Box Plots\"></a>\n",
    "\n",
    "## Section 3.1: Attributes: Box Plots\n",
    "\n",
    "The code below creates a Box Plot for each of the non-binned attributes (columns 0 - 18 and 4124-4125). \n",
    "\n",
    "<b>Runtime Expectation:</b> The following three cells run in about 5 to 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.patches import Polygon\n",
    "#import seaborn as sns\n",
    "#\n",
    "# Box Plot: Attribute 1 - Shot Length\n",
    "#\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(6.7, 3))\n",
    "#\n",
    "#axes = df_final.boxplot(column=cols[1:2], by='Dimension Index', patch_artist=True, ax=ax)\n",
    "#\n",
    "#axes.set_xlabel('Non-commercial vs. Commercial')   # Non-commericial == -1, Commercial == +1\n",
    "#\n",
    "#plt.subplots_adjust(top=1.5)\n",
    "#plt.suptitle('')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#\n",
    "# Box Plot: Attributes 2-18 - Motion Distribution-Mean to Fundamental Frequency-Variance\n",
    "#\n",
    "#fig, ax = plt.subplots(8, 2, figsize=(15, 26))\n",
    "#\n",
    "#axes = df_final.boxplot(column=cols[2:18], by='Dimension Index', patch_artist=True, ax=ax)\n",
    "#\n",
    "#for i in axes:\n",
    "#    i.set_xlabel('Non-commercial vs. Commercial')   # Non-commericial == -1, Commercial == +1\n",
    "#\n",
    "#plt.subplots_adjust(top=1.5)\n",
    "#plt.suptitle('')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#\n",
    "# Box Plot: Attributes 4124-4125 - Edge change Ratio-Mean to Edge change Ratio-Variance\n",
    "#\n",
    "#fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "#\n",
    "#axes = df_final.boxplot(column=cols[122:124], by='Dimension Index', patch_artist=True, ax=ax)\n",
    "#\n",
    "#for i in axes:\n",
    "#    i.set_xlabel('Non-commercial vs. Commercial')   # Non-commericial == -1, Commercial == +1\n",
    "#\n",
    "#plt.subplots_adjust(top=1.5)\n",
    "#plt.suptitle(\"\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 3.2: Attributes: Hexbin Plots\"></a>\n",
    "\n",
    "## Section 3.2: Attributes: Hexbin Plots\n",
    "\n",
    "The hex bin plots below compare the relationship between the different news sources. The charts visualize the linear relationship that all of the news networks have with the means. They will also help identify outliers.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#\n",
    "#fig, ax = plt.subplots(2, 3, figsize=(20,12))\n",
    "#\n",
    "# Plot all five datasets / broadcast\n",
    "#\n",
    "#df_final.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='All Five Networks',ax=ax[0,0])\n",
    "#\n",
    "# Plot each dataset / broadcast\n",
    "#\n",
    "#df_bbc.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='BBC',ax=ax[0,1])\n",
    "#df_cnn.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='CNN',ax=ax[0,2])\n",
    "#df_cnnibn.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='CNNIBN',ax=ax[1,0])\n",
    "#df_ndtv.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='NDTV',ax=ax[1,1])\n",
    "#df_timesnow.plot('Spectral Centroid-Mean','Spectral Roll off-Mean',kind='hexbin',gridsize=30,title='TIMESNOW',ax=ax[1,2])\n",
    "#\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 3.3: Principal Component Analysis (PCA)\"></a>\n",
    "\n",
    "## Section 3.3: Principal Component Analysis (PCA)\n",
    "\n",
    "The code below creates and X-array of non-binned attributes and a Y-array of the target (Dimension Index: Commercial (+1) or Non-commercial (-1)). The X-array is then scaled and the PCA algorithm is executed against that scaled array. The components array is then concatenated with the target array and converted into a Pandas dataset for further manipulation.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.78734651  3.73473747  2.27796866  1.82692531  0.93404041  0.77218619\n",
      "  0.64801603  0.5556868   0.4809975   0.34358321  0.17267961  0.15922282\n",
      "  0.10505322  0.077286    0.065199    0.0280053   0.0203011   0.01090364]\n",
      "[ 0.32151677  0.20748382  0.12655284  0.10149507  0.05189073  0.0428989\n",
      "  0.03600061  0.03087125  0.02672188  0.01908781  0.00959324  0.00884564\n",
      "  0.00583625  0.00429363  0.00362214  0.00155584  0.00112783  0.00060575]\n",
      "1.0\n",
      "Wall time: 1.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x = df_final.loc[:, cols[1:19]].values\n",
    "y = df_final.loc[:,['Dimension Index']].values\n",
    "\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "pca = PCA(n_components=18)\n",
    "\n",
    "components = pca.fit_transform(x)\n",
    "\n",
    "col_names = ['Dimension Index','PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12','PC13','PC14',\n",
    "    'PC15','PC16','PC17','PC18']\n",
    "\n",
    "df_pca = pd.DataFrame(np.hstack((y, components)), columns=col_names)\n",
    "\n",
    "df_pca.head()\n",
    "\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.21 s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAFGCAYAAAB+JLTIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFeP/A7gnfRnlCg7sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23740a15cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import seaborn as sb\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from pylab import rcParams\n",
    "\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sb.heatmap(df_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 4: Modeling\"></a>\n",
    "\n",
    "## Section 4: Modeling\n",
    "\n",
    "<a id=\"Section 4.1: Logistic Regression\"></a>\n",
    "\n",
    "## Section 4.1: Logistic Regression\n",
    "\n",
    "The following cell runs a logistic regression using the default parameters. Unlike the Support Vector Models (discussed below), the Logistic Regression models use all the attributes and all the instances in the concatenated dataset (129,685 rows).\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "num_cv_iterations = 1\n",
    "\n",
    "df_test = df_final.copy(deep=True)   # <-- All 129,685 rows\n",
    "\n",
    "y = df_test['Dimension Index'].values\n",
    "del df_test['Dimension Index']\n",
    "\n",
    "X = df_test[cols[1:]].values   # <-- ALL attirube (except the target variable)\n",
    "\n",
    "num_instances = len(y)\n",
    "\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size=0.2)\n",
    "                         \n",
    "print(cv_object)\n",
    "\n",
    "lr_clf = LogisticRegression()   # Default parms\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X, y):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train, y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test) # get test set predictions\n",
    "    \n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "    print(\"Accuracy:\", acc )\n",
    "    print(\"Confusion matrix:\\n\", conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the accuracy score for this Logistic Regresson is about 0.84 with default paramaters. The value of accuracy can be calculated from the confusion matrix as (1310 + 2,673) / (1310 + 2,673 + 343 + 183) or the sum of (True Positives + True Negatives) / (the sum of all values: True Positive, True Negative, False Positve, and False Negative).\n",
    "\n",
    "### Section 4.1.1: Attribute Weights\n",
    "\n",
    "The cell below prints out the weight for each attribute in the Logistic Regression.\n",
    "\n",
    "<b>Runtime expectation:</b> The cell below runs in less than a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "weights = lr_clf.coef_.T   # Transpose to make a column vector\n",
    "\n",
    "variable_names = df_final.columns\n",
    "\n",
    "for coef, name in zip(weights, variable_names):\n",
    "    print(name, 'has weight of', coef[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.1.2: Attribute Weights (with scaling)\n",
    "\n",
    "The cell below prints out the weight for each attribute in the Logistic Regression (after scaling). Note that accuracy improves a bit (about .88 vs. about .85).\n",
    "\n",
    "<b>Runtime expectation:</b> The cell below runs in about 10 to 15 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train)\n",
    "X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05)\n",
    "lr_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled)\n",
    "\n",
    "acc = mt.accuracy_score(y_test, y_hat)\n",
    "conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "print('Accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "zip_vars = zip(lr_clf.coef_.T, df_final.columns)\n",
    "zip_vars = sorted(zip_vars)\n",
    "\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.1.3: Plot the Weights (with scaling)\n",
    "\n",
    "With over 100 attributes, the follow bar plot is not very pretty. (The labels, for example, are unreadable). It does, however, give a visual clue into the attributes and their weights.\n",
    "\n",
    "<b>Runtime expectation:</b> The cell below runs in just a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0], index=df_final.columns[1:])\n",
    "\n",
    "weights.plot(kind='bar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4.1.4: Interpretting the Weights\n",
    "\n",
    "The first 10 sorted attributes (by weight after scaling) is shown below:\n",
    "\n",
    "> Motion Distribution-Variance has weight of -2.51974347148  \n",
    "> Short time energy-Mean has weight of -1.39512309456  \n",
    "> ZCR-Variance has weight of -1.33520317615  \n",
    "> Motion Distribution-Bin 13 has weight of -1.20928601292  \n",
    "> Attribute 58 should be Bin 40 has weight of -0.818619501619  \n",
    "> Text area distribution-Bin 7-Mean has weight of -0.712396779843  \n",
    "> Text area distribution-Bin 12-Variance has weight of -0.690287908028  \n",
    "> Spectral Flux-Variance has weight of -0.678467583285  \n",
    "> Spectral Roll off-Variance has weight of -0.572899154928  \n",
    "> Fundamental Frequency-Variance has weight of -0.391339499589  \n",
    "\n",
    "Surprisingly, the attribute 'Shot Length' is not in the top 10 most important weighted attributes.\n",
    "\n",
    "### Section 4.1.5: Adjusting paramaters (the C value)\n",
    "\n",
    "The Logistic Regression model above used default paramaters in the classifier. The cell below changes the C value from 0.05 to 1.50 (5% to 150%) to see if it can capture the highest accuracy within that C value range.\n",
    "\n",
    "<b>Runtime expectation:</b> The following cell runs in about 10 to 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "def do_lr(c):\n",
    "    lr_clf = LogisticRegression(C=c)   # Default parms, except the C value\n",
    "\n",
    "    for train_indices, test_indices in cv_object.split(X, y):\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "    \n",
    "        X_test = X[test_indices]\n",
    "        y_test = y[test_indices]\n",
    "\n",
    "        lr_clf.fit(X_train, y_train)\n",
    "\n",
    "        y_hat = lr_clf.predict(X_test)\n",
    "\n",
    "        acc = mt.accuracy_score(y_test, y_hat)\n",
    "        conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "        return acc, conf\n",
    "\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "\n",
    "c_parms = [5]\n",
    "\n",
    "for i in np.arange(1, 30):\n",
    "    c_parms.append(c_parms[i-1] + int(5))\n",
    "\n",
    "highest_acc = 0.0\n",
    "highest_c = 0.0\n",
    "highest_conf = [[]]\n",
    "\n",
    "for i in np.arange(0, 30):\n",
    "    acc, conf = do_lr(c_parms[i] / 100)\n",
    "\n",
    "    if acc > highest_acc:\n",
    "        highest_acc = acc\n",
    "        highest_c = c_parms[i]\n",
    "        highest_conf = conf\n",
    "        \n",
    "print('Highest accuracy:', highest_acc, ', C:', highest_c, ', Confusion matrix:', highest_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the cell above will capture the C value with the highest accuracy (which is generally close to the default).\n",
    "\n",
    "### Section 4.1.6: Adjusting paramaters (the solvers)\n",
    "\n",
    "The cell below uses default parameters except for the solver='sag' (Stochastic Average Gradient descent solver). \n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr_clf = LogisticRegression(solver='sag')    # Default parms: penalty='l2', C=1.0, class_weight=None, \n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X, y):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train, y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test) # get test set predictions\n",
    "\n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "    print(\"Accuracy:\", acc )\n",
    "    print(\"Confusion matrix:\\n\", conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the cell above, the accuracy score for this linear regresson, sag with an accuracy of about 0.78 is much lower than using the default solver='liblinear' with an accuracy generally greater than 0.88.\n",
    "\n",
    "The cell below uses default parameters except for the solver='saga' (another Stochastic Average Gradient descent solver).\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 30 to 40 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr_clf = LogisticRegression(solver='saga')   # Default parms: penalty='l2', C=1.0, class_weight=None,\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X, y):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    \n",
    "    lr_clf.fit(X_train, y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test) # get test set predictions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    \n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "    print(\"Accuracy:\", acc )\n",
    "    print(\"Confusion matrix:\\n\", conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the cell above, solver='saga' has an accuracy of about 0.77, which is also much lower than using the default solver='liblinear' having an accuracy generally greater around 0.85 or so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 4.2: Support Vector Machines\"></a>\n",
    "\n",
    "## Section 4.2: Support Vector Machines\n",
    "\n",
    "While the Logistic Regression models ran in 30 seconds or so (and about 15 minutes for optimized parameter selection), the Support Vector Machine models tend to run much longer. All five datases concatenated (df_concat), for example, takes nearly an hour to run on the same machine. Consequently, the cell below uses the CNN dataset (about one-fifth of concatenated dataset) to get an idea of how well the SVM models are predicting the target variable: Commercial vs. Non-commercial. (Based on the Hex Bin plots, the CNN dataset was visually similar to the CNNIBN, NDTV, and TIMESNOW datasets, whereas the BBC dataset was somewhat different.)\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 5 to 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "num_cv_iterations = 1\n",
    "\n",
    "df_test = df_cnn.copy(deep=True)   # <-- 1/5 of the df_concat dataset (22,545 rows of 129,865)\n",
    "\n",
    "y = df_test['Dimension Index'].values\n",
    "del df_test['Dimension Index']\n",
    "\n",
    "X = df_test[cols[1:]].values   # <-- All atttributes (excepts the target variable)\n",
    "\n",
    "num_instances = len(y)\n",
    "\n",
    "print(num_instances)\n",
    "\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size=0.2)\n",
    "                         \n",
    "print(cv_object)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC()    # Support Vector Machine using the default parms\n",
    "\n",
    "for train_index, test_index in cv_object.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_hat = svm_clf.predict(X_test) # get test set predictions\n",
    "\n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Confusion matrix:\\n\", conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the output above, the SVC classifier run against just the CNN dataset takes at least 5 minutes with an accuracy of about 0.64 (quite low compared to the Logistic Regression models).\n",
    "\n",
    "### Section 4.2.1: SGDClassifier\n",
    "\n",
    "In contrast, the SGDClassifier classifier below runs the enitre dataset (all five broadcasts) in less than a second with an improved accuracy of about 0.77 (but still lagging behind Logistic Regression).\n",
    "\n",
    "<b>Runtime Expectation</b>: The following cell runs in less than a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_cv_iterations = 1\n",
    "\n",
    "df_test = df_final.copy(deep=True)   # <-- 1/5 of the df_concat dataset (22,545 rows of 129,865)\n",
    "\n",
    "y = df_test['Dimension Index'].values\n",
    "del df_test['Dimension Index']\n",
    "\n",
    "X = df_test[cols[1:]].values   # <-- All atttributes (excepts the target variable)\n",
    "\n",
    "num_instances = len(y)\n",
    "\n",
    "print(num_instances)\n",
    "\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size=0.2)\n",
    "                         \n",
    "print(cv_object)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_clf = SGDClassifier()   # Default loss='hinge' -- SVM\n",
    "\n",
    "print(svm_clf)\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X, y):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    svm_clf.fit(X_train, y_train)  # train object\n",
    "\n",
    "    y_hat = svm_clf.predict(X_test) # get test set predictions\n",
    "    \n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "    print(\"Accuracy:\", acc )\n",
    "    print(\"Confusion matrix:\\n\", conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section 4: Modeling (New)\"></a>\n",
    "\n",
    "## <span style=\"color:red\">Section 4: Modeling (New)</span>\n",
    "\n",
    "<a id=\"Section 4.1: Linear Regression\"></a>\n",
    "\n",
    "## <span style=\"color:red\">Section 4.1: Linear Regression</span>\n",
    "\n",
    "Although is is clear from the attribute weighting that the attribute 'Shot Length' is not in the top 10 most important weighted attributes, it is still going to be useful to run a Linear Regression to attempt to estimate its value.\n",
    "\n",
    "<b>Runtime Expectation:</b> The following cell runs in about 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 123.]\n",
      " [ 124.]\n",
      " [ 109.]\n",
      " ..., \n",
      " [ 100.]\n",
      " [  60.]\n",
      " [  25.]]\n",
      "ShuffleSplit(n_splits=1, random_state=None, test_size=0.2, train_size=None)\n",
      ".\n",
      "Coefficients: \n",
      " [-0.000776]\n",
      "Mean squared error: 84510.28\n",
      "Variance score: -0.16\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "num_cv_iterations = 1\n",
    "\n",
    "df_test = df_final.copy(deep=True)   # <-- All 129,685 rows\n",
    "\n",
    "y = df_test['Dimension Index'].values\n",
    "del df_test['Dimension Index']\n",
    "\n",
    "X = df_test[cols[1:2]].values   # <-- ALL attirube (except the target variable)\n",
    "\n",
    "print(X)\n",
    "\n",
    "num_instances = len(y)\n",
    "\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size=0.2)\n",
    "                         \n",
    "print(cv_object)\n",
    "\n",
    "#lr_clf = LogisticRegression()   # Default parms\n",
    "lr_clf = LinearRegression()   # Default parms\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X, y):\n",
    "    print('.')\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    lr_clf.fit(X_train, y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test) # get test set predictions\n",
    "\n",
    "    print('Coefficients: \\n', lr_clf.coef_)\n",
    "    print(\"Mean squared error: %.2f\" % mean_squared_error(X_test, y_hat))\n",
    "    print('Variance score: %.2f' % r2_score(X_test, y_hat))\n",
    "\n",
    "    \n",
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.plot(X_test, y_hat, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_indices, test_indices in cv_object.split(X, y):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    lr_clf.fit(X_train, y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test) # get test set predictions\n",
    "    \n",
    "    acc = mt.accuracy_score(y_test, y_hat)\n",
    "    conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "    print(\"Accuracy:\", acc )\n",
    "    print(\"Confusion matrix:\\n\", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df_test = df_bbc_bow.copy(deep=True)\n",
    "\n",
    "y = df_test['Dimension Index'].values\n",
    "del df_test['Dimension Index']\n",
    "\n",
    "X = df_test[cols_bow[1:]].values   # <-- ALL attirubes (except the target variable)\n",
    "\n",
    "cv_object = StratifiedKFold(n_splits=10)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150,random_state=1)\n",
    "\n",
    "acc = cross_val_score(clf, X, y=y, cv=cv_object)\n",
    "\n",
    "print (\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100)\n",
    "\n",
    "#lr_clf = LinearRegression(C=50)   # Default parms, except the C value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mdo_lr\u001b[1;34m(c)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'C'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "def do_lr(c):\n",
    "    lr_clf = LinearRegression(C=c)   # Default parms, except the C value\n",
    "\n",
    "    for train_indices, test_indices in cv_object.split(X, y):\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "    \n",
    "        X_test = X[test_indices]\n",
    "        y_test = y[test_indices]\n",
    "\n",
    "        lr_clf.fit(X_train, y_train)\n",
    "\n",
    "        y_hat = lr_clf.predict(X_test)\n",
    "\n",
    "        acc = mt.accuracy_score(y_test, y_hat)\n",
    "        conf = mt.confusion_matrix(y_test, y_hat)\n",
    "\n",
    "        return acc, conf\n",
    "\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "\n",
    "c_parms = [5]\n",
    "\n",
    "for i in np.arange(1, 30):\n",
    "    c_parms.append(c_parms[i-1] + int(5))\n",
    "\n",
    "highest_acc = 0.0\n",
    "highest_c = 0.0\n",
    "highest_conf = [[]]\n",
    "\n",
    "for i in np.arange(0, 30):\n",
    "    acc, conf = do_lr(c_parms[i] / 100)\n",
    "\n",
    "    if acc > highest_acc:\n",
    "        highest_acc = acc\n",
    "        highest_c = c_parms[i]\n",
    "        highest_conf = conf\n",
    "        \n",
    "print('Highest accuracy:', highest_acc, ', C:', highest_c, ', Confusion matrix:', highest_conf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
